{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIF control NODDI analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### v1.2 ~ 30/08/2019  \n",
    "Niall Bourke (n.bourke@imperial.ac.uk)  \n",
    "-Based on Maria Yanez Lopez original NODDI notebook  \n",
    "\n",
    "##### Pre-requisites:\n",
    "- Python 2.7 required for AMICO (Notebook in Py3)\n",
    "- spams needs to be setup via conda\n",
    "(https://github.com/daducci/AMICO/issues/61)\n",
    "- DATA INPUT from BIDS source dir\n",
    "\n",
    "##### Scripts needed for it to work:  \n",
    "(Hardcoded and need to be ammended - could call in Jupyter cell?)\n",
    "- AMICO_modeling.py    \n",
    "- Normalise_bvec.py    \n",
    "- hpcrunarrayjob.sh/ hpcSubmit  \n",
    "\n",
    "#### There are issues submitting as a job on the cluster.. Modeling has been run locally"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project = \"BIO-AX-TBI\"\n",
    "\n",
    "directory = (\"/rds/general/user/nbourke/ephemeral/\" + project + \"/data/\")\n",
    "\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    \n",
    "raw = (\"/rds/general/project/c3nl_djs_imaging_data/live/data/raw/\" + project + \"/\")\n",
    "source = (\"/rds/general/project/c3nl_djs_imaging_data/live/data/sourcedata/\")\n",
    "wd = (\"/rds/general/user/nbourke/ephemeral/\" + project + \"/\")\n",
    "setup = (wd + \"/setup.sh\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $setup\n",
    "\n",
    "$(: Project label) \n",
    "project=\"BIO-AX-TBI\" \n",
    "\n",
    "$(:  Where is the RAW directory?)\n",
    "# export rawDir=/rds/general/project/c3nl_shared/live/${project}/sourcedata\n",
    "\n",
    "$(: dependencies)\n",
    "export dep=/rds/general/project/c3nl_shared/live/dependencies/\n",
    "export templates=/rds/general/user/nbourke/home/templates\n",
    "export wd=/rds/general/user/nbourke/ephemeral/${project}\n",
    "\n",
    "# Define modules    \n",
    "fsl=\"module load fsl\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "echo $wd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data valadation - check data is correctly pulled from raw to source data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from os import path\n",
    "import fnmatch\n",
    "    \n",
    "for subject in os.listdir(raw):\n",
    "    #print(subject)  \n",
    "    subDir = (source + \"sub-\" + subject + \"/\")\n",
    "    \n",
    "    try:\n",
    "        for session in os.listdir(subDir):\n",
    "            in_file = (subDir + session + \"/dwi/msdwi/sub-\" + subject + \"_\" + session + \"_msdwi.nii\")\n",
    "\n",
    "            try:\n",
    "                f = open(in_file)\n",
    "                print(in_file + ' File exists')\n",
    "                f.close()\n",
    "            except FileNotFoundError:\n",
    "                print(in_file + ' WARNING: File does not exist')\n",
    "    except FileNotFoundError:\n",
    "        print(subject + ' WARNING: SUBJECT NOT FOUND')\n",
    "    except NotADirectoryError:\n",
    "        print(subject + ' WARNING: Directory NOT FOUND')\n",
    "                    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 1: File management - create an organised data directory\n",
    "#### Pulling from BIDS sourcedata structure "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "source=/rds/general/project/c3nl_djs_imaging_data/live/data/sourcedata/;\n",
    "project=BIO-AX-TBI ; # EDIT HERE\n",
    "modeled=/rds/general/project/c3nl_djs_imaging_data/live/analysis/NODDI/BIOAX_NODDI/AMICO/modeled_data\n",
    "\n",
    "\n",
    "wd=${EPHEMERAL}/${project}/;\n",
    "echo -n \"\" > ${wd}/msdwiMissingData.txt;\n",
    "\n",
    "for subject in `ls /rds/general/project/c3nl_djs_imaging_data/live/data/raw/${project}`; \n",
    "do \n",
    "    if [ ! -d ${source}/sub-${subject} ]; then \n",
    "        echo \"${subject} not found in sourcedata\"\n",
    "    else\n",
    "        \n",
    "        for session in `ls ${source}/sub-${subject}/`;\n",
    "        do\n",
    "            #if [ ! -d $modeled/${session} ]; then\n",
    "            if [ ! -d $wd/${session} ]; then\n",
    "\n",
    "                if [ ! -d ${source}/sub-${subject}/${session}/dwi/msdwi ]; then \n",
    "                    echo \"msdwi data not found for ${session}\" >> ${wd}/msdwiMissingData.txt;\n",
    "                else\n",
    "                #ls ${source}/sub-${subject}/${session}/dwi/msdwi/*_v3_msdwi.nii\n",
    "                    mkdir -p ${wd}/data/sub-${subject}/${session}/dwi/msdwi\n",
    "                    mkdir -p ${wd}/data/sub-${subject}/${session}/anat/T1w\n",
    "                    cp ${source}/sub-${subject}/${session}/dwi/msdwi/*  ${wd}/data/sub-${subject}/${session}/dwi/msdwi/;\n",
    "                    cp ${source}/sub-${subject}/${session}/anat/T1w/*  ${wd}/data/sub-${subject}/${session}/anat/T1w/;\n",
    "                fi\n",
    "            fi\n",
    "        done\n",
    "    fi\n",
    "    \n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These have a different sequence names for some reason - add to config file and rerun\n",
    "sub-CH0010001\n",
    "sub-CH0010002\n",
    "\n",
    "sub-CH0010006 has two visit 1s - first one missing bvals & bvecs so removed this session\n",
    "\n",
    "Pilots - have B0 scan but not full protocal\n",
    "CIF1655\n",
    "CIF1656 - rescaned has data on second visit\n",
    "CIF2188\n",
    "\n",
    "CIF2369 - had old conversion which is now deleated, current one is fine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Notes on calculating acquisition parameters\n",
    "*requires scan card (header unlikey to contain the right info)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "acqparams = Echo spacing (ms) x 0.001 (time) x (EPI factor - 1) \n",
    "\n",
    "CIF acqparams\n",
    "\n",
    "0 -1 0 0.09144\n",
    "0 1 0 0.09144\n",
    "\n",
    "Lausanne acqparam\n",
    "\n",
    "0 -1 0 0.09398\n",
    "0 1 0 0.09398\n",
    "\n",
    "\n",
    "[x y z time_between_centre_of_echo]\n",
    "xyz > Phase encoding direction - positive/negative blips\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing acqparam.txt for each subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import fnmatch\n",
    "\n",
    "\n",
    "DATADIR = \"/rds/general/user/nbourke/ephemeral/BIO-AX-TBI/data/\"\n",
    "    \n",
    "for subject in os.listdir(DATADIR):\n",
    "    if fnmatch.fnmatch(subject, 'sub-CIF*'):\n",
    "        print(subject)\n",
    "        for session in os.listdir(DATADIR+subject):\n",
    "            message = '0 -1 0 0.09144\\n0 1 0 0.09144\\n'\n",
    "            file_name =  (DATADIR+\"/\"+subject+\"/\"+session+\"/dwi/msdwi/acqparams.txt\")\n",
    "            with open(file_name, 'w') as fp:\n",
    "                fp.write(message)\n",
    "    \n",
    "    elif fnmatch.fnmatch(subject, 'sub-CH*'):\n",
    "        print(subject)\n",
    "        for session in os.listdir(DATADIR+subject):\n",
    "            message = '0 -1 0 0.09398\\n0 1 0 0.09398\\n'\n",
    "            file_name =  (DATADIR+\"/\"+subject+\"/\"+session+\"/dwi/msdwi/acqparams.txt\")\n",
    "            with open(file_name, 'w') as fp:\n",
    "                fp.write(message)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set index file \n",
    "\n",
    "- reads volumes and sets text file (not a single hardcoded file as some scanns had 99vol and others 100)\n",
    "- index file contains 1 for num of volumes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nibabel as nb\n",
    "import os\n",
    "import os.path\n",
    "from os import path\n",
    "    \n",
    "DATADIR = \"/rds/general/user/nbourke/ephemeral/BIO-AX-TBI/data/\"\n",
    "    \n",
    "for subject in os.listdir(DATADIR):\n",
    "    for session in os.listdir(DATADIR+subject):\n",
    "        out_file = os.path.abspath(DATADIR+subject+\"/\"+session+'/dwi/msdwi/index.txt')\n",
    "        in_file=(DATADIR+subject+\"/\"+session+\"/dwi/msdwi/\"+subject+\"_\"+session+\"_msdwi.nii\")\n",
    "        \n",
    "        try:\n",
    "            print (in_file)\n",
    "            vols = nb.load(in_file).get_data().shape[-1]\n",
    "            print(vols)\n",
    "            np.savetxt(out_file, np.ones((vols,), dtype=np.int), fmt=\"%i\", newline=\" \")\n",
    "        except IOError:\n",
    "            print(\"WARNING \" + in_file + \" NOT FOUND!!\")\n",
    "            \n",
    "        \n",
    "#         if in_file is None:\n",
    "#             print (in_file, \"File does not exist\") \n",
    "#         else:\n",
    "#             print (in_file)\n",
    "#             vols = nb.load(in_file).get_data().shape[-1]\n",
    "#             print(vols)\n",
    "#             np.savetxt(out_file, np.ones((vols,), dtype=np.int), fmt=\"%i\", newline=\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stage 2: Pre-processing diffusion data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correct for eddy distortion and motion in the data\n",
    "#### Topup (requires B0 reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "wd=${EPHEMERAL}/BIO-AX-TBI;\n",
    "DATADIR=${wd}/data;\n",
    "echo -n \"\" > ${wd}/topup.txt;\n",
    "\n",
    "sub=`ls $DATADIR`;\n",
    "for subject in `echo $sub`; \n",
    "do  \n",
    "    \n",
    "    for session in `ls ${DATADIR}/${subject}/`;\n",
    "    do  \n",
    "        filePath=${DATADIR}/${subject}/${session}/dwi/msdwi; \n",
    "        echo \"module load fsl; fslroi ${filePath}/${subject}_${session}_msdwi.nii ${filePath}/${subject}_${session}_AP_B0.nii 0 1; fslmerge -t ${filePath}/${subject}_${session}_combined_AP_PA_B0 ${filePath}/${subject}_${session}_AP_B0.nii ${filePath}/${subject}_${session}_b0_reversed.nii; topup --imain=${filePath}/${subject}_${session}_combined_AP_PA_B0 --datain=${filePath}/acqparams.txt --config=${FSLDIR}/etc/flirtsch/b02b0.cnf --out=${filePath}/topup --iout=${filePath}/hifi_b0 ; fslmaths ${filePath}/hifi_b0 -Tmean ${filePath}/hifi_b0; bet ${filePath}/hifi_b0 ${filePath}/hifi_b0_brain -m\" >>  ${wd}/topup.txt;   \n",
    "    done;\n",
    "done;\n",
    "\n",
    "        # repol - dealing with slice drop out from motion\n",
    "        # cnr = contrast noise ratio maps for QC\n",
    "        \n",
    "    # Run jobs\n",
    "    /rds/general/project/c3nl_shared/live/dependencies/hpcSubmit ${wd}/topup.txt 03:00:00 6 8Gb; \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eddy\n",
    "\n",
    "#### Neeed to swap brain mask here for something better like the one from FreeSurfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "wd=${EPHEMERAL}/BIO-AX-TBI;\n",
    "DATADIR=${wd}/data;\n",
    "echo -n \"\" > ${wd}/eddy.txt;\n",
    "\n",
    "# ----------------------------\n",
    "\n",
    "sub=`ls $DATADIR`;\n",
    "for subject in `echo $sub`; \n",
    "do  \n",
    "    \n",
    "    for session in `ls ${DATADIR}/${subject}/`;\n",
    "    do  \n",
    "        filePath=${DATADIR}/${subject}/${session}/dwi/msdwi\n",
    "        # Generate a brain mask\n",
    "        echo \"module load fsl; eddy_openmp --imain=${filePath}/${subject}_${session}_msdwi.nii --mask=${filePath}/hifi_b0_brain_mask --acqp=${filePath}/acqparams.txt --index=${filePath}/index.txt --bvecs=${filePath}/${subject}_${session}_msdwi.bvec --bvals=${filePath}/${subject}_${session}_msdwi.bval --topup=${filePath}/topup --repol --cnr_maps --out=${filePath}/ec_data\" >>  ${wd}/eddy.txt;   \n",
    "    done;\n",
    "done;\n",
    "\n",
    "        # repol - dealing with slice drop out from motion\n",
    "        # cnr = contrast noise ratio maps for QC\n",
    "        \n",
    "    # Run jobs\n",
    "    /rds/general/project/c3nl_shared/live/dependencies/hpcSubmit ${wd}/eddy.txt 12:00:00 4 6Gb; \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalise bvec  - *Not run on human data, not required!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script bash\n",
    "\n",
    "# python /rds/general/user/nbourke/home/projects/NODDI_HPC_fitting/scripts/Normalise_bvec.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Import python libraries\n",
    "# import sys, os \n",
    "# import numpy as np\n",
    "# from dipy.io import read_bvals_bvecs\n",
    "# from dipy.core.geometry  import normalized_vector\n",
    "\n",
    "# DATADIR = \"/rds/general/user/nbourke/ephemeral/BIOAX_NODDI/data/\"\n",
    "\n",
    "# for subject in os.listdir(DATADIR):\n",
    "#     for session in os.listdir(DATADIR+subject):\n",
    "#         #Normalizing bvec file:\n",
    "#         bvals, bvecs = read_bvals_bvecs(DATADIR+subject+\"/\"+session+\"/dwi/msdwi/\"+subject+\"_\"+session+\"_msdwi.bval\", DATADIR+subject+\"/\"+session+\"/dwi/msdwi/rotated_bvec\") \n",
    "#         print(DATADIR+subject+\"/\"+session+\"/dwi/msdwi/\"+subject+\"_\"+session+\"_msdwi.bval\")\n",
    "#         print(DATADIR+subject+\"/\"+session+\"/dwi/msdwi/rotated_bvec\")\n",
    "\n",
    "\n",
    "#         nvec = normalized_vector(bvecs)\n",
    "#         #Changing the b0 bvecs to [0 0 1]:\n",
    "#         nvec[np.isnan(nvec)] = 0\n",
    "#         nvec[0:4,2] = 1\n",
    "#         #Transposing and saving the new normalized bvec file\n",
    "#         nvec = np.transpose(nvec)\n",
    "#         np.savetxt(DATADIR + \"/\" + subject + \"/\" + session + \"/dwi/msdwi/norm_bvec.bvec\", nvec, fmt='%.18e', delimiter=' ', newline='\\n')\n",
    "#         continue\n",
    "    \n",
    "#     else:\n",
    "#         continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AMICO is fussy on the structure of data so lets learn how to do some data manipulation in python\n",
    "pathlib - py3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import python libraries\n",
    "import sys, os \n",
    "import pathlib\n",
    "from shutil import copyfile\n",
    "\n",
    "# pathlib - py3\n",
    "\n",
    "DATADIR = \"/rds/general/user/nbourke/ephemeral/BIO-AX-TBI/data/\"\n",
    "\n",
    "for subject in os.listdir(DATADIR):\n",
    "    for session in os.listdir(DATADIR+subject):\n",
    "        \n",
    "        directory=(\"/rds/general/user/nbourke/ephemeral/BIO-AX-TBI/AMICO/\" + session + \"/\")\n",
    "        if not os.path.exists(directory):\n",
    "            os.makedirs(directory)\n",
    "        \n",
    "        #Normalizing bvec file:\n",
    "        src_bval=(DATADIR+subject+\"/\"+session+\"/dwi/msdwi/\"+subject+\"_\"+session+\"_msdwi.bval\")\n",
    "        src_bvec=(DATADIR+subject+\"/\"+session+\"/dwi/msdwi/ec_data.eddy_rotated_bvecs\")\n",
    "        src_ec=(DATADIR+subject+\"/\"+session+\"/dwi/msdwi/ec_data.nii.gz\")\n",
    "        src_mask=(DATADIR+subject+\"/\"+session+\"/dwi/msdwi/hifi_b0_brain_mask.nii.gz\")\n",
    "\n",
    "        dst_bval=(directory + \"msdwi.bval\")\n",
    "        dst_bvec=(directory + \"rotated_bvec\")\n",
    "        dst_ec=(directory + \"ec_data.nii.gz\")\n",
    "        dst_mask=(directory + \"hifi_b0_brain_mask.nii.gz\")\n",
    "        \n",
    "        #print(src_bval)\n",
    "        #print(dst_bval)\n",
    "        \n",
    "        \n",
    "        bvalPath = pathlib.Path(src_bval)\n",
    "        if bvalPath.exists ():\n",
    "            copyfile(src_bval, dst_bval)\n",
    "        else:\n",
    "            print (src_bval, \"File not exist\")\n",
    "        \n",
    "        bvecPath = pathlib.Path(src_bvec)\n",
    "        if bvecPath.exists ():\n",
    "            copyfile(src_bvec, dst_bvec)\n",
    "        else:\n",
    "            print (src_bvec, \"File not exist\")\n",
    "        \n",
    "        ecPath = pathlib.Path(src_ec)\n",
    "        if ecPath.exists ():\n",
    "            copyfile(src_ec, dst_ec)\n",
    "        else:\n",
    "            print (src_ec, \"File not exist\")\n",
    "        \n",
    "        maskPath = pathlib.Path(src_mask)\n",
    "        if maskPath.exists ():\n",
    "            copyfile(src_mask, dst_mask)\n",
    "        else:\n",
    "            print (src_mask, \"File not exist\")\n",
    "    \n",
    "    else:\n",
    "        continue\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Run AMICO python NODDI fitting, submitting to the cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This step uses https://github.com/daducci/AMICO/blob/master/doc/demos/NODDI_01.md.\n",
    "\n",
    "* Beware there is some hard coding in the python script that is called!  \n",
    "* This didnt work on cluster so ran it locally "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "#import amico \n",
    "\n",
    "echo -n \"\" > ~/NODDI_fitting.txt\n",
    "\n",
    "dataDir=/rds/general/user/nbourke/home/CIF-CONTROLS/AMICO/\n",
    "\n",
    "for subject in `ls $dataDir`; do \n",
    "    echo \"python ${HOME}/projects/NODDI_HPC_fitting/scripts/AMICO_modeling.py $dataDir $subject\" >> ~/NODDI_fitting.txt\n",
    "done\n",
    "    \n",
    "    # Run jobs\n",
    "    /rds/general/project/c3nl_shared/live/dependencies/hpcSubmit ~/NODDI_fitting.txt 01:00:00 1 2Gb\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the state of the submitted cluster jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!qstat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean output and error files after checking them\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stage 2 - Moving the images to standard space, to be able to do statistics...\n",
    "\n",
    "## This is a quick registration using fsl, may want to go an extra step and use DTI-TK\n",
    "** HACKED, Not standard format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "dep=\"/rds/general/project/c3nl_shared/live/dependencies/\"\n",
    "wd=~/March2020/data;\n",
    "echo -n \"\" > ${wd}/dtifitJob.txt\n",
    "job=${wd}/dtifitJob.txt\n",
    "\n",
    "template=/rds/general/user/nbourke/home/templates/FMRIB58_FA_1mm.nii.gz\n",
    "# ----------------------------\n",
    "\n",
    "for visit in v1 v2 v3 hc rugby unknown ; \n",
    "    do \n",
    "    \n",
    "    for subject in `ls ${wd}/${visit}/`; do\n",
    "        #echo $subject\n",
    "        echo \"module load fsl; dtifit --data=${wd}/${visit}/${subject}/ec_data.nii.gz --out=${wd}/${visit}/${subject}/dti --mask=${wd}/${visit}/${subject}/hifi_b0_brain_mask.nii --bvecs=${wd}/${visit}/${subject}/rotated_bvec --bvals=${wd}/${visit}/${subject}/msdwi.bval -w\" >> ${job}   \n",
    "    done;\n",
    "done;\n",
    "\n",
    "    # Run job\n",
    "    ${dep}/hpcSubmit ${job} 02:00:00 1 2Gb\n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"\n",
    "    head ${job}    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting CORRECT fa scalers & Register"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "template=/rds/general/user/nbourke/home/templates/FMRIB58_FA_1mm.nii.gz\n",
    "dep=\"/rds/general/project/c3nl_shared/live/dependencies/\"\n",
    "wd=~/March2020/data;\n",
    "\n",
    "export DTITK_ROOT=/apps/dti-tk/2.3.1/; export PATH=$PATH:$DTITK_ROOT/bin:$DTITK_ROOT/utilities:$DTITK_ROOT/scripts:$DTITK_ROOT/lib:$DTITK_ROOT/include;\n",
    "\n",
    "echo -n \"\" > echo -n \"\" > ${wd}/flirt.txt\n",
    "job=${wd}/flirt.txt\n",
    "# ----------------------------\n",
    "\n",
    "# set DTITK path #\n",
    "export DTITK_ROOT=/apps/dti-tk/2.3.1/\n",
    "export PATH=$PATH:$DTITK_ROOT/bin:$DTITK_ROOT/utilities:$DTITK_ROOT/scripts:$DTITK_ROOT/lib:$DTITK_ROOT/include\n",
    "                    \n",
    "for visit in v1 v2 v3 hc rugby unknown ; do\n",
    "    \n",
    "    for subject in `ls ${wd}/${visit}/`; do \n",
    "          echo \"module load fsl; fsl_to_dtitk ${wd}/${visit}/${subject}/dti; TVtool -in ${wd}/${visit}/${subject}/dti_dtitk.nii.gz -out ${wd}/${visit}/${subject}/fa.nii.gz -fa ; flirt -in ${wd}/${visit}/${subject}/fa.nii.gz -ref $template -omat ${wd}/${visit}/${subject}/flirt.mat -out ${wd}/${visit}/${subject}/MNI_${subject}_fa.nii.gz\" >> ${job}  \n",
    "    done\n",
    "done\n",
    "\n",
    "    # Run job\n",
    "    ${dep}/hpcSubmit ${job} 02:00:00 1 2Gb \n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"\n",
    "    head ${job}   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Taking the mat file from the registration of the eddy corrected data to MNI space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "template=/rds/general/user/nbourke/home/templates/FMRIB58_FA_1mm.nii.gz\n",
    "dep=\"/rds/general/project/c3nl_shared/live/dependencies/\"\n",
    "wd=~/March2020/data;\n",
    "echo -n \"\" > ${wd}/flirtNODDI.txt\n",
    "job=${wd}/flirtNODDI.txt\n",
    "# ----------------------------\n",
    "\n",
    "for visit in v1 v2 v3 hc rugby unknown ; \n",
    "    do\n",
    "    for subject in `ls ${wd}/${visit}/`; do\n",
    "        for modality in `ls ${wd}/${visit}/${subject}/AMICO/NODDI/*.nii.gz`;\n",
    "        do\n",
    "        mod=`basename $modality`\n",
    "        #echo $mod\n",
    "    \n",
    "        echo \"module load fsl; flirt -in ${wd}/${visit}/${subject}/AMICO/NODDI/${mod} -ref $template -init ${wd}/${visit}/${subject}/flirt.mat -applyxfm -out ${wd}/${visit}/${subject}/AMICO/NODDI/MNI_${mod}.nii.gz\" >> ${wd}/flirtNODDI.txt    \n",
    "    \n",
    "        done\n",
    "    done\n",
    "done\n",
    "    \n",
    "    # Run job\n",
    "    ${dep}/hpcSubmit ${job} 02:00:00 1 2Gb \n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"\n",
    "    head ${job}   \n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Think about the voxelwise statistical tests to be run and how the data needs to be formed for it\n",
    "\n",
    "1. Repeated measures ANOVA in patients with three timepoints \n",
    "2. Reapeated measures ANOVE in patients with two timepoints\n",
    "3. Between group comparison of patients v1,v2,v3 with controls (Three seperate analysis?)\n",
    "\n",
    "    - Scanner as a factor..b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIF data - predicting LARS & FrSBe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "template=/rds/general/user/nbourke/home/templates/FMRIB58_FA_1mm.nii.gz\n",
    "dep=\"/rds/general/project/c3nl_shared/live/dependencies/\"\n",
    "wd=~/March2020/data/analysis;\n",
    "\n",
    "\n",
    "module load fsl\n",
    "# ----------------------------\n",
    "\n",
    "for ii in `ls ${wd}`; \n",
    "    do\n",
    "        ls ${wd}/${ii}/MNI_${ii}_fa.nii.gz >> ${wd}/FA_path.txt\n",
    "        ls ${wd}/${ii}/AMICO/NODDI/MNI_FIT_ICVF.nii.gz >> ${wd}/ICVF_path.txt\n",
    "        ls ${wd}/${ii}/AMICO/NODDI/MNI_FIT_OD.nii.gz >> ${wd}/OD_path.txt\n",
    "        ls ${wd}/${ii}/AMICO/NODDI/MNI_FIT_ISOVF.nii.gz >> ${wd}/ISOVF_path.txt\n",
    "done\n",
    "\n",
    "\n",
    "for mod in FA ICVF OD ISOVF; \n",
    "    do\n",
    "    fslmerge -t ${wd}/tbss/${mod} `cat ${wd}/${mod}_path.txt` \n",
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script bash\n",
    "\n",
    "# template=/rds/general/user/nbourke/home/templates/FMRIB58_FA_1mm.nii.gz\n",
    "# dep=\"/rds/general/project/c3nl_shared/live/dependencies/\"\n",
    "# wd=${EPHEMERAL}/Jan2020\n",
    "# echo -n \"\" > ${wd}/flirtNODDI.txt\n",
    "# job=${wd}/flirtNODDI.txt\n",
    "\n",
    "# module load fsl\n",
    "# # ----------------------------\n",
    "\n",
    "# mkdir ${wd}/tbss\n",
    "\n",
    "# for visit in v1 v2 v3 con ; do\n",
    "    \n",
    "#     for subject in `ls ${wd}/${visit}/`; do\n",
    "         \n",
    "#         ls  ${wd}/${visit}/${subject}/MNI_*fa.nii.gz >>  ${wd}/subj_fa.txt\n",
    "        \n",
    "#         for modality in `ls ${wd}/${visit}/${subject}/AMICO/NODDI/*.nii.gz`;\n",
    "#         do\n",
    "#         mod=`basename $modality`\n",
    "#         mo=$(echo ${mod} | cut -d '.' -f1)\n",
    "#         m=$(echo ${mo##*_})\n",
    "#         #echo $m\n",
    "\n",
    "#         echo \"${wd}/${visit}/${subject}/AMICO/NODDI/MNI_FIT_${m}.nii.gz\" >>  ${wd}/subj_${m}.txt                       \n",
    "         \n",
    "#         done\n",
    "#     done\n",
    "# done\n",
    "\n",
    "                   \n",
    "#          fslmerge -t ${wd}/tbss/all_ICVF `cat ${wd}/subj_ICVF.txt`   \n",
    "#              fslmerge -t ${wd}/tbss/all_OD `cat ${wd}/subj_OD.txt`    \n",
    "#                  fslmerge -t ${wd}/tbss/all_ISOVF `cat ${wd}/subj_ISOVF.txt`  \n",
    "#                     fslmerge -t ${wd}/tbss/all_FA `cat ${wd}/subj_fa.txt`  \n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4D files with patients accross three timepoints\n",
    "#### Check what is common across all visits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "template=/rds/general/user/nbourke/home/templates/FMRIB58_FA_1mm.nii.gz\n",
    "dep=\"/rds/general/project/c3nl_shared/live/dependencies/\"\n",
    "wd=${EPHEMERAL}/Jan2020\n",
    "echo -n \"\" > ${wd}/flirtNODDI.txt\n",
    "job=${wd}/flirtNODDI.txt\n",
    "\n",
    "module load fsl\n",
    "# ----------------------------\n",
    "\n",
    "# # Check what is common across all visits\n",
    "# for visit in v3 ; do\n",
    "#      for subject in `ls ${wd}/${visit}/`; \n",
    "#         do\n",
    "#         s=${subject::(-3)}\n",
    "#         sub=${s:15}\n",
    "#         echo $sub >> ${wd}/longSubj.txt\n",
    "\n",
    "#         ls  ${wd}/v1/*-${sub}_v1/MNI_*fa.nii.gz\n",
    "#         ls  ${wd}/v2/*-${sub}_v2/MNI_*fa.nii.gz\n",
    "\n",
    "#     done\n",
    "# done  \n",
    "\n",
    "echo \"\" > ${wd}/conSubj.txt\n",
    "# Controls\n",
    "for visit in HC ; do\n",
    "     for subject in `ls ${wd}/${visit}/`; \n",
    "        do\n",
    "        echo $subject >> ${wd}/conSubj.txt\n",
    "    done\n",
    "done "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With V3\n",
    "\n",
    "#### Empty\n",
    "- CH0010024_v2  \n",
    "\n",
    "\n",
    "#### unprocessed\n",
    "- ses-2018-09-20-CH0010019_v1 : inconsistant b0 & b0_reverse dimensions..\n",
    "\n",
    "- CH0010016_v1  : failing NODDI modeling\n",
    "\n",
    "### With V2  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove the missing subjects and add full paths to data in a text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "dep=\"/rds/general/project/c3nl_shared/live/dependencies/\"\n",
    "wd=${EPHEMERAL}/Jan2020\n",
    "# ----------------------------\n",
    "\n",
    "# # Ridiculous way to loop - but it's 7am and I want it in this order to match fsl glm example  \n",
    "#     for ii in `cat ${wd}/longSubj.txt`; \n",
    "#         do\n",
    "#         for v in v1;\n",
    "#             do\n",
    "#             ls ${wd}/${v}/*-${ii}_${v}/MNI_*-${ii}_${v}_fa.nii.gz >> ${wd}/longFA_path.txt\n",
    "#             ls ${wd}/${v}/*-${ii}_${v}/AMICO/NODDI/MNI_FIT_ICVF.nii.gz >> ${wd}/longICVF_path.txt\n",
    "#             ls ${wd}/${v}/*-${ii}_${v}/AMICO/NODDI/MNI_FIT_OD.nii.gz >> ${wd}/longOD_path.txt\n",
    "#             ls ${wd}/${v}/*-${ii}_${v}/AMICO/NODDI/MNI_FIT_ISOVF.nii.gz >> ${wd}/longISOVF_path.txt\n",
    "#             ls ${wd}/${v}/*-${ii}_${v}/AMICO/NODDI/MNI_FIT_dir.nii.gz >> ${wd}/longDIR_path.txt\n",
    "#         done\n",
    "#     done\n",
    "#     for ii in `cat ${wd}/longSubj.txt`; \n",
    "#         do\n",
    "#         for v in v2;\n",
    "#             do\n",
    "#             ls ${wd}/${v}/*-${ii}_${v}/MNI_*-${ii}_${v}_fa.nii.gz >> ${wd}/longFA_path.txt\n",
    "#             ls ${wd}/${v}/*-${ii}_${v}/AMICO/NODDI/MNI_FIT_ICVF.nii.gz >> ${wd}/longICVF_path.txt\n",
    "#             ls ${wd}/${v}/*-${ii}_${v}/AMICO/NODDI/MNI_FIT_OD.nii.gz >> ${wd}/longOD_path.txt\n",
    "#             ls ${wd}/${v}/*-${ii}_${v}/AMICO/NODDI/MNI_FIT_ISOVF.nii.gz >> ${wd}/longISOVF_path.txt\n",
    "#             ls ${wd}/${v}/*-${ii}_${v}/AMICO/NODDI/MNI_FIT_dir.nii.gz >> ${wd}/longDIR_path.txt\n",
    "#         done\n",
    "#     done\n",
    "#     for ii in `cat ${wd}/longSubj.txt`; \n",
    "#         do\n",
    "#         for v in v3;\n",
    "#             do\n",
    "#             ls ${wd}/${v}/*-${ii}_${v}/MNI_*-${ii}_${v}_fa.nii.gz >> ${wd}/longFA_path.txt\n",
    "#             ls ${wd}/${v}/*-${ii}_${v}/AMICO/NODDI/MNI_FIT_ICVF.nii.gz >> ${wd}/longICVF_path.txt\n",
    "#             ls ${wd}/${v}/*-${ii}_${v}/AMICO/NODDI/MNI_FIT_OD.nii.gz >> ${wd}/longOD_path.txt\n",
    "#             ls ${wd}/${v}/*-${ii}_${v}/AMICO/NODDI/MNI_FIT_ISOVF.nii.gz >> ${wd}/longISOVF_path.txt\n",
    "#             ls ${wd}/${v}/*-${ii}_${v}/AMICO/NODDI/MNI_FIT_dir.nii.gz >> ${wd}/longDIR_path.txt\n",
    "#         done\n",
    "#     done\n",
    "\n",
    "\n",
    "    for ii in `cat ${wd}/conSubj.txt`; \n",
    "        do\n",
    "        for v in HC;\n",
    "            do\n",
    "            ls ${wd}/${v}/${ii}/MNI_${ii}_fa.nii.gz >> ${wd}/conFA_path.txt\n",
    "            ls ${wd}/${v}/${ii}/AMICO/NODDI/MNI_FIT_ICVF.nii.gz >> ${wd}/conICVF_path.txt\n",
    "            ls ${wd}/${v}/${ii}/AMICO/NODDI/MNI_FIT_OD.nii.gz >> ${wd}/conOD_path.txt\n",
    "            ls ${wd}/${v}/${ii}/AMICO/NODDI/MNI_FIT_ISOVF.nii.gz >> ${wd}/conISOVF_path.txt\n",
    "        done\n",
    "    done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stack volumes into 4D file to analyse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "template=/rds/general/user/nbourke/home/templates/FMRIB58_FA_1mm.nii.gz\n",
    "dep=\"/rds/general/project/c3nl_shared/live/dependencies/\"\n",
    "wd=${EPHEMERAL}/Jan2020\n",
    "echo -n \"\" > ${wd}/fslMerge.txt\n",
    "job=${wd}/fslMerge.txt\n",
    "\n",
    "# ----------------------------\n",
    "\n",
    "for mod in FA ICVF OD ISOVF; \n",
    "    do\n",
    "    echo \"module load fsl; fslmerge -t ${wd}/tbss/con_${mod} \\`cat ${wd}/tbss/con${mod}_path.txt\\` \" >> ${job} # \\ to pretect special characters\n",
    "done\n",
    "\n",
    "    # Run job\n",
    "    ${dep}/hpcSubmit ${job} 01:00:00 1 6Gb \n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"\n",
    "    head ${job}   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup design matrix and contrast as per\n",
    "\n",
    "https://fsl.fmrib.ox.ac.uk/fsl/fslwiki/GLM\n",
    "\n",
    "Statistics Jargon Decoder: Repeated Measures ANOVA (2). This is again a \"Repeated Measures ANOVA\" with one fixed and one random factor, the same as the previous example except that the fixed factor has three levels. Fitting such a mixed effects model with Ordinary Least Squares (OLS) (as done in Feat) requires an assumption of compound symmetry. This is the state of equal variance and intra-subject correlations being equal. That is, Cov(scan1,scan2) = Cov(scan1,scan3) = Cov(scan2,scan3).\n",
    "\n",
    "The assumption of this design, compound symmetry, is probably a reasonable assumption unless, say, the data are from a long or irregularly sampled longitudinal study. For example, if scan 1 and 2 are collected 1 week apart and scan 3 is collected 1 year later, it's unlikely that they are equally correlated. Note, also, only intrasubject contrasts are valid with this design. For example, a [1 1 1] contrast cannot be assessed; if such a contrast is of interest, the individual measures should be averaged with fslmaths and then studied in a one-sample t-test (assuming they are difference measures, and can be so suitably analysed)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extraction from  tbbs_3 & 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "\n",
    "template=/rds/general/user/nbourke/home/templates/FMRIB58_FA_1mm.nii.gz\n",
    "wd=${EPHEMERAL}/Jan2020\n",
    "${fsl}\n",
    "echo -n \"\" > ${wd}/fslSkel.txt\n",
    "job=${wd}/fslSkel.txt\n",
    "\n",
    "# ----------------------------\n",
    "    \n",
    "    subProj=controls\n",
    "    \n",
    "    # create mean FA\n",
    "    echo \"creating valid mask and mean FA\"\n",
    "    fslmaths ${wd}/tbss/${subProj}/con_FA -max 0 -Tmin -bin ${wd}/tbss/${subProj}/mean_FA_mask -odt char\n",
    "    fslmaths ${wd}/tbss/${subProj}/con_FA -mas ${wd}/tbss/mean_FA_mask${wd}/tbss/${subProj}/long_FA\n",
    "    fslmaths ${wd}/tbss/${subProj}/con_FA -Tmean ${wd}/tbss/${subProj}/mean_FA\n",
    "\n",
    "    # create skeleton\n",
    "    echo \"skeletonising mean FA\"\n",
    "    tbss_skeleton -i ${wd}/tbss/${subProj}/mean_FA -o ${wd}/tbss/${subProj}/mean_FA_skeleton\n",
    "\n",
    "    echo \"creating skeleton mask using threshold 0.2\"\n",
    "    fslmaths ${wd}/tbss/${subProj}/mean_FA_skeleton -thr 0.3 -bin ${wd}/tbss/${subProj}/mean_FA_skeleton_mask\n",
    "\n",
    "    echo \"creating skeleton distancemap (for use in projection search)\"\n",
    "    fslmaths ${wd}/tbss/${subProj}/mean_FA_mask -mul -1 -add 1 -add ${wd}/tbss/${subProj}/mean_FA_skeleton_mask ${wd}/tbss/${subProj}/mean_FA_skeleton_mask_dst\n",
    "    distancemap -i ${wd}/tbss/${subProj}/mean_FA_skeleton_mask_dst -o ${wd}/tbss/${subProj}/mean_FA_skeleton_mask_dst\n",
    "\n",
    "    echo \"projecting all FA data onto skeleton\"\n",
    "    tbss_skeleton -i ${wd}/tbss/${subProj}/mean_FA -p 0.3 ${wd}/tbss/${subProj}/mean_FA_skeleton_mask_dst ${FSLDIR}/data/standard/LowerCingulum_1mm ${wd}/tbss/${subProj}/con_FA ${wd}/tbss/${subProj}/con_FA_skeletonised\n",
    "\n",
    "\n",
    "    for ALTIM in ICVF OD ISOVF; \n",
    "        do\n",
    "        echo \"tbss_skeleton -i ${wd}/tbss/${subProj}/mean_FA -p 0.3 ${wd}/tbss/${subProj}/mean_FA_skeleton_mask_dst ${FSLDIR}/data/standard/LowerCingulum_1mm ${wd}/tbss/${subProj}/con_FA ${wd}/tbss/${subProj}/con_${ALTIM}_skeletonised -a ${wd}/tbss/${subProj}/con_${ALTIM}\" >> ${job}   \n",
    "    done\n",
    "    \n",
    "    \n",
    "    # Run job\n",
    "    ${dep}/hpcSubmit ${job} 01:00:00 1 6Gb \n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"\n",
    "    head ${job}   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tract stats\n",
    "\n",
    "This takes a while, should be submitted!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "\n",
    "template=/rds/general/user/nbourke/home/templates/FMRIB58_FA_1mm.nii.gz\n",
    "tractDir=/rds/general/user/nbourke/home/templates/Corrected_Tracts\n",
    "wd=${EPHEMERAL}/Jan2020/tbss\n",
    "${fsl}\n",
    "# ----------------------------\n",
    "\n",
    "\n",
    "# Find the tract masks\n",
    "    cd ${tractDir}\n",
    "    TRACTS=`ls *.gz`\n",
    "\n",
    "# Nested for loop\n",
    "for mod in ICVF OD ISOVF FA; do    \n",
    "    for project in controls #longitudinal; \n",
    "        do\n",
    "        \n",
    "        # 1 Copy subjects\n",
    "        cp ${wd}/long${mod}_path.txt ${wd}/${project}/tractStats/${mod}/AAA_subj.txt;\n",
    "        \n",
    "        \n",
    "        # 2 Whole brain summary values\n",
    "        mkdir -p ${wd}/${project}/tractStats/${mod}\n",
    "        echo \"wholeBrain_${mod}\" > ${wd}/${project}/tractStats/${mod}/wholeBrainStats.txt\n",
    "        fslstats -t ${wd}/${project}/con_${mod}_skeletonised.nii.gz -M >> ${wd}/${project}/tractStats/${mod}/wholeBrainStats.txt\n",
    "        \n",
    "\n",
    "        # 3 Tract values\n",
    "        for i in $TRACTS; do\n",
    "            #echo $i\n",
    "            k=$(echo ${i} | cut -d '.' -f1)            \n",
    "            echo ${mod}_${k} > ${wd}/${project}/tractStats/${mod}/${mod}_${k}.txt\n",
    "            fslstats -t ${wd}/${project}/con_${mod}_skeletonised.nii.gz -k ${tractDir}/$i -M >> ${wd}/${project}/tractStats/${mod}/${mod}_${k}.txt   \n",
    "        done\n",
    "    done\n",
    "    # paste  -d \",\" `ls $DATADIR/${project}/tractStats/${mod}/` >> $DATADIR/${project}/${mod}_tract_stats.csv    \n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voxelwise analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "\n",
    "template=/rds/general/user/nbourke/home/templates/FMRIB58_FA_1mm.nii.gz\n",
    "tractDir=/rds/general/user/nbourke/home/templates/Corrected_Tracts\n",
    "wd=${EPHEMERAL}/Jan2020/tbss\n",
    "${fsl}\n",
    "\n",
    "echo -n \"\" > ${wd}/vx.txt\n",
    "job=${wd}/vx.txt\n",
    "\n",
    "# ----------------------------\n",
    "\n",
    "# Nested for loop\n",
    "for mod in ICVF OD ISOVF FA; do    \n",
    "    for project in longitudinal; \n",
    "        do\n",
    "  \n",
    "        #- set output -#\n",
    "        output=${wd}/${project}/randomise_output/${mod}\n",
    "        mkdir -p ${output}\n",
    "\n",
    "        #- set variables -#\n",
    "        input=${wd}/${project}/con_${mod}.nii.gz\n",
    "        FA_skeleton_mask=${wd}/${project}/mean_FA_skeleton_mask.nii.gz\n",
    "        design=${wd}/${project}/designGLM.mat    #design/design.mat\n",
    "        contrast=${wd}/${project}/designGLM.con   #design/contrast.con\n",
    "        \n",
    "        ~/c3nl_tools/pbs_randomise_par -wt 24:00:00 -mem 14Gb -i ${input} -o ${output}/tbss_${mod} -m $FA_skeleton_mask -d $design -t $contrast -n 5000 --T2 -V\n",
    "        \n",
    "    done\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "---\n",
    "\n",
    "\n",
    "# QC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set data dir and copy cell into terminal\n",
    "\n",
    "### START COPY ###\n",
    "\n",
    "template=/Users/niallbourke/hpc/templates/FMRIB58_FA_1mm.nii.gz\n",
    "DATADIR=/Users/niallbourke/hpc/eph/NODDIDATA/analysis/\n",
    "\n",
    "for project in ukXsectional ukV1V2; do\n",
    "    \n",
    "    for subject in `ls $DATADIR/${project}/data/`; do\n",
    "        \n",
    "        fa=`ls ${DATADIR}/${project}/data/${subject}/MNI_*fa.nii.gz` \n",
    "        echo \"$fa\" >>  ${DATADIR}/${project}/subj_fa.txt\n",
    "        \n",
    "        for modality in `ls ${DATADIR}/${project}/data/${subject}/AMICO/NODDI/MNI*.nii.gz`;\n",
    "        do\n",
    "        \n",
    "        echo \"Next scan set: $subject\"\n",
    "        fsleyes $template $modality ;\n",
    "\n",
    "        done;\n",
    "    done;\n",
    "done\n",
    "\n",
    "### END COPY ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# temp processing for missed subj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%script bash\n",
    "\n",
    "wd=/rds/general/user/nbourke/home/eph/BIO-AX-TBI/missed/unproc;\n",
    "DATADIR=${wd};\n",
    "echo -n \"\" > ${wd}/topup.txt;\n",
    "\n",
    "module load fsl\n",
    "\n",
    "sub=sub-CH0010019\n",
    "for subject in `echo $sub`;\n",
    "    do\n",
    "    for session in `ls ${DATADIR}/${subject}/`;\n",
    "        do\n",
    "        filePath=${DATADIR}/${subject}/${session}/dwi/msdwi;\n",
    "        module load fsl;\n",
    "        fslroi ${filePath}/${subject}_${session}_msdwi.nii ${filePath}/${subject}_${session}_AP_B0.nii 0 1;\n",
    "        fslmerge -t ${filePath}/${subject}_${session}_combined_AP_PA_B0 ${filePath}/${subject}_${session}_AP_B0.nii ${filePath}/${subject}_${session}_b0_reversed.nii;\n",
    "        topup --imain=${filePath}/${subject}_${session}_combined_AP_PA_B0 --datain=${filePath}/acqparams.txt --config=${FSLDIR}/etc/flirtsch/b02b0.cnf --out=${filePath}/topup --iout=${filePath}/hifi_b0 ;\n",
    "        fslmaths ${filePath}/hifi_b0 -Tmean ${filePath}/hifi_b0;\n",
    "        bet ${filePath}/hifi_b0 ${filePath}/hifi_b0_brain -m\n",
    "        eddy_openmp --imain=${filePath}/${subject}_${session}_msdwi.nii --mask=${filePath}/hifi_b0_brain_mask --acqp=${filePath}/acqparams.txt --index=${filePath}/index.txt --bvecs=${filePath}/${subject}_${session}_msdwi.bvec --bvals=${filePath}/${subject}_${session}_msdwi.bval --topup=${filePath}/topup --repol --cnr_maps --out=${filePath}/ec_data\n",
    "\n",
    "    done;\n",
    "done;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
