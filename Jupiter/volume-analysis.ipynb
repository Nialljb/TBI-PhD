{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Volumetric analysis\n",
    "\n",
    "* Last run for PTBI ~ April 2020 \n",
    "  \n",
    "Matlab dependencies by Neil Graham and Greg Scott\n",
    "\n",
    "This notebook takes a set of scans and tells you what the volumes of grey matter, white matter and CSF are. It also lets you run a voxelwise comparison (voxel based morphometry) between the two groups (patients versus controls) to see whether the volume at each voxel is significantly different. Eg. Do patients have smaller brains (ie are they more atrophic) than controls?\n",
    "\n",
    "The notebook uses SPM12 (UCL) to do most of the heavy lifting, and then FSL for the stats. You might find the SPM manual useful: https://www.fil.ion.ucl.ac.uk/spm/doc/manual.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "You will need:\n",
    "\n",
    "-Data stored in BIDS format  \n",
    "\n",
    "* hpcwrapmatlab.sh\n",
    "* hpcrunarrayjob.sh\n",
    "* segment_t1.m\n",
    "* make_template.m\n",
    "* generate_flowfields.m\n",
    "* move_to_mni.m\n",
    "\n",
    "All of these scripts should be in the dependencies folder now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of volumes from T1 sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's define some paths and get FSL loaded etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "##### python cell\n",
    "    1. enter project ID\n",
    "    2. If this project doesn't exist in in the temporary space, create it\n",
    "    3. Set importnat paths that will be used\n",
    "    4. Make a setup script to save bash variables in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project = \"PTBI\" \n",
    "\n",
    "directory = (\"/rds/general/project/c3nl_djs_imaging_data/ephemeral/\" + project + \"/data/\")\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    \n",
    "raw = (\"/rds/general/project/c3nl_djs_imaging_data/live/data/raw/\" + project + \"/\")\n",
    "source = (\"/rds/general/project/c3nl_djs_imaging_data/live/data/sourcedata/\")\n",
    "workingDir = (\"/rds/general/project/c3nl_djs_imaging_data/ephemeral/\" + project + \"/\")\n",
    "setup = (workingDir + \"/setup.sh\" )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### bash cell\n",
    "This cell adds bash variables you want to save to a setup script, which can then be called in future python cells. \n",
    "\n",
    "1. Add project name\n",
    "2. Add paths of interest\n",
    "3. Define modules that will be needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /rds/general/project/c3nl_djs_imaging_data/ephemeral/PTBI//setup.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile $setup\n",
    "\n",
    "$(: Project label) \n",
    "project=\"PTBI\"\n",
    "\n",
    "$(:  Where is the RAW directory?)\n",
    "export raw=/rds/general/project/c3nl_djs_imaging_data/live/data/raw/${project};\n",
    "#export subjects=/rds/general/user/nbourke/home/projects/${project}/scripts/rawSubj.txt\n",
    "\n",
    "$(: dependencies)\n",
    "export dep=/rds/general/project/c3nl_shared/live/dependencies/\n",
    "export templates=/rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/templates\n",
    "export workingDir=/rds/general/project/c3nl_djs_imaging_data/ephemeral/${project}\n",
    "\n",
    "# Define modules    \n",
    "fsl=\"module load fsl\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rds/general/project/c3nl_djs_imaging_data/ephemeral/PTBI\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "echo $workingDir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Copy data\n",
    "\n",
    "Copy data in BIDS format from source directory into a temporary working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "echo $workingDir\n",
    "# ----------------\n",
    "\n",
    "sourceDir=/rds/general/project/c3nl_djs_imaging_data/live/data/sourcedata/\n",
    "\n",
    "for ii in `ls -d ${raw}/*`; \n",
    "    do\n",
    "    sub=`basename $ii`\n",
    "    \n",
    "    for ses in `ls ${sourceDir}/sub-${sub}`;\n",
    "        do\n",
    "        mkdir -p ${workingDir}/data/sub-${sub}/${ses}/anat/T1w/\n",
    "        cp ${sourceDir}/sub-${sub}/${ses}/anat/T1w/sub-${sub}_${ses}_T1w.nii ${workingDir}/data/sub-${sub}/${ses}/anat/T1w/sub-${sub}_${ses}_T1w.nii\n",
    "    done        \n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a list of T1 scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "\n",
    "# module load fsl\n",
    "#----------------------------\n",
    "\n",
    "# setup log dir\n",
    "if [ ! -d ${workingDir}/commandLogs/ ]; then\n",
    "    echo \"Making log dir!\"\n",
    "    mkdir ${workingDir}/commandLogs/\n",
    "fi\n",
    "#\n",
    "\n",
    "# Make a list of all T1 scans\n",
    "echo -n \"\" > ${workingDir}/t1_list.txt\n",
    "for s in `ls -d ${workingDir}/data/*`;\n",
    "    do\n",
    "    subj=`basename ${s}`\n",
    "    for ses in `ls ${workingDir}/data/${subj}`; \n",
    "        do \n",
    "        echo ${s}/${ses}/anat/T1w/${subj}_${ses}_T1w.nii >> ${workingDir}/t1_list.txt\n",
    "    done\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1. Run segmentation jobs\n",
    "- one subject did not compleate for some reason (PTBI039). This was taken and run again "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "\n",
    "# module load fsl\n",
    "#----------------------------\n",
    "\n",
    "# Segment T1 data\n",
    "echo -n \"\" > ${workingDir}/commandLogs/segmentationJobs.txt\n",
    "for subject in `cat ${workingDir}/t1_list.txt`\n",
    "    do\n",
    "    echo \"${dep}/hpcwrapmatlab.sh \\\"maxNumCompThreads(3); segment_t1('${subject}');\\\"\" >> ${workingDir}/commandLogs/segmentationJobs.txt \n",
    "done;\n",
    "\n",
    "job=${workingDir}/commandLogs/segmentationJobs.txt\n",
    "            \n",
    "    # Run job\n",
    "    ${dep}/hpcSubmit ${job} 01:00:00 3 6Gb\n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"\n",
    "    head ${job}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Optional: check on your job progress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!qstat -f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### After the job has completed look at the output:\n",
    "\n",
    "Four each subject you should have the following files:\n",
    "* subject....nii - this is the original untouched nifti - we could later delete it from here as it is stored in the sourcedata folder, in order to save space \n",
    "* c1 ....   - this is the grey matter segmented output\n",
    "* c2 ....   - this is the white matter segmented output\n",
    "* c3 ....   - this is the CSF segmented output\n",
    "* rc1 ... rc2  etc.. - this is a rigidly aligned GM segmented output (useful for later when we want to move files to 'standard space' such as MNI)\n",
    "* seg8 - has details of the segmentation to save SPM time if the software needs to reference the files later on\n",
    "\n",
    "And most importantly:\n",
    "* ...... vols.txt - this has your tissue volumes in it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vital step: Have a look at your scans to make sure the segmentation has worked properly in each case\n",
    "We can even generate some commands for you to use in the terminal with FSL.\n",
    "\n",
    "These are designed so it will be as painless as possible. Load up the terminal, connect to the HPC, make sure you do module load fsl\n",
    "\n",
    "1. Copy this cell into terminal to run all subjects (quit by pressing ctrl+c in terminal)\n",
    "2. Run this cell to get commands to copy into terminal to run one at a time\n",
    "\n",
    "*You want to ensure that the wm and gm are separated nicely and in a way which you think is appropriate.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# fn = dir('/rds/general/user/nbourke/ephemeral/fa/*.gz');\n",
    "\n",
    "# % Now we want to view as a movie for QA purposes. \n",
    "# figure;ax = gca;\n",
    "# % use the following to force the Current figure handle to appear outside the live script\n",
    "# set(gcf,'Visible','on')\n",
    "# for ii=1:numel(fn)\n",
    "#     plotNifti([fn(ii).folder,filesep,fn(ii).name],ax);\n",
    "#     drawnow % will tell Matlab to create animation\n",
    "#     pause(0.2) % how long to pause between loading the next image\n",
    "# end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can bundle up all of the vols.txt files into a big CSV for convenience, and put this in your notebook folder (within a subfolder called volumetric_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "echo $workingDir\n",
    "#------------------\n",
    "\n",
    "if [ -d ${workingDir}/volumetric_results ]   \n",
    "    then\n",
    "    echo \"results folder ready\";\n",
    "    else\n",
    "    mkdir -p ${workingDir}/volumetric_results\n",
    "    echo \"results folder made\";\n",
    "fi\n",
    "   \n",
    "    echo \"subject,gm_vol,wm_vol,csf_vol\" > ${workingDir}/volumetric_results/volumes.csv \n",
    "    for subject in `ls ${workingDir}/data/`\n",
    "        do\n",
    "        for ses in `ls ${workingDir}/data/${subject}/`; \n",
    "            do \n",
    "            volsfile=${workingDir}/data/$subject/${ses}/anat/T1w/*_vols.txt       \n",
    "            if [ -f ${volsfile} ]\n",
    "               then\n",
    "               echo -n \"${ses}\" >> ${workingDir}/volumetric_results/volumes.csv;\n",
    "               tail -n 1 ${volsfile} >> ${workingDir}/volumetric_results/volumes.csv;\n",
    "            fi\n",
    "        done\n",
    "    done;\n",
    "    \n",
    "echo \"done\";"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You could download these CSVs into the analysis package of your choice and do some comparisons using the summary measures.\n",
    "\n",
    "Eg. t-test comparing the GM volume in patients versus controls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voxelwise statistics \n",
    "### (and steps to get the images in standard space to facilitate this)\n",
    "In order to do comparisons on the shapes of different brains they need to be moved into 'standard space' such as MNI. SPM can do this for us using 'DARTEL', an approach which preserves volume information on moving.\n",
    "\n",
    "Then we can use FSL randomise to do voxelwise comparisons between groups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. First make a 'study-specific' template\n",
    "This is an average image of your subjects. Rather than going straight to standard space like MNI, it's better to go via a template. You could use all your subjects for this, or a selection of them. Ideally it should be 50% patients 50% controls.  Run the next cell to make a file listing which subjects to use. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file subjects_for_volumetric_template.txt\n",
    "sub-control001\n",
    "sub-control002\n",
    "sub-control003\n",
    "sub-patient001\n",
    "sub-patient002\n",
    "sub-patient003"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make the template.\n",
    "\n",
    "This can take a while so you can increase the number from 3 hours to something more generous if you've got lots of subjects.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "#------------------\n",
    "\n",
    "# this uses the RC rigidly aligned files from the segmentation output : if you want to have a look at them use this in bash\n",
    "\n",
    "echo -n \"\" > ${workingDir}/commandLogs/templateJob.txt\n",
    "job=${workingDir}/commandLogs/templateJob.txt\n",
    "\n",
    "    files=\"\"\n",
    "  \n",
    "echo \"\" > ${workingDir}/subj.txt   \n",
    "\n",
    "for subject in `ls ${workingDir}/data/`\n",
    "    do\n",
    "    for ses in `ls ${workingDir}/data/${subject}/`; \n",
    "        do \n",
    "        echo ${workingDir}/data/${subject}/${ses} >> ${workingDir}/subj.txt   \n",
    "    done\n",
    "done\n",
    "           \n",
    "for subject in `cat ${workingDir}/subj.txt`;\n",
    "     do\n",
    "     rc1=`ls ${subject}/anat/T1w/rc1*T1w.nii`;\n",
    "     rc2=`ls ${subject}/anat/T1w/rc2*T1w.nii`;\n",
    "     rc3=`ls ${subject}/anat/T1w/rc3*T1w.nii`;\n",
    "\n",
    "     if [ -z \"${files}\" ]; then\n",
    "         files=\"'${rc1}','${rc2}','${rc3}'\";\n",
    "     else\n",
    "         files=\"${files},'${rc1}','${rc2}','${rc3}'\";\n",
    "     fi\n",
    "    \n",
    "done;\n",
    "            \n",
    "     echo \"${dep}/hpcwrapmatlab.sh \\\"maxNumCompThreads(3); make_template('Template', ${files});\\\"\" > ${job};\n",
    "              \n",
    "    # Run job\n",
    "    ${dep}/hpcSubmit ${job} 08:00:00 3 6Gb\n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"\n",
    "    head ${job}      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the job is done, you need to move the completed template files to a nice new folder, as by default they are dumped into the first subject's folder \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "#------------------\n",
    "\n",
    "line=$(head -n 2  ${workingDir}/subj.txt)\n",
    "echo ${line}\n",
    "\n",
    "mkdir -p ${workingDir}/templates/;\n",
    "cp ${line}/anat/T1w/Template_* ${workingDir}/templates/;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Make flowfields to the newly made group template for each subject's scan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "echo $workingDir\n",
    "#------------------\n",
    " \n",
    "    \n",
    "template_basename=\"Template\"\n",
    "template=${workingDir}/templates/${template_basename}\n",
    "\n",
    "unset files;\n",
    "echo \"\" > ${workingDir}/flowfields.txt\n",
    "job=${workingDir}/flowfields.txt\n",
    "\n",
    "for subject in `cat ${workingDir}/subj.txt` \n",
    "do\n",
    "\n",
    "     files=\"\"\n",
    "\n",
    "     rc1=`ls ${subject}/anat/T1w/rc1*T1w.nii`;\n",
    "     rc2=`ls ${subject}/anat/T1w/rc2*T1w.nii`;\n",
    "     rc3=`ls ${subject}/anat/T1w/rc3*T1w.nii`;\n",
    "\n",
    "     files=\"'${rc1}','${rc2}','${rc3}'\";\n",
    "\n",
    "     if [ -f $rc1 ];\n",
    "     then\n",
    "\n",
    "     echo \"${dep}/hpcwrapmatlab.sh \\\"generate_flowfields('${template}', ${files})\\\"\" >> ${job}; \n",
    "\n",
    "     else\n",
    "     echo \"No rc1 file for ${subject} at visit ${visit}\";\n",
    "     fi\n",
    "    \n",
    "     unset files;\n",
    "\n",
    "done\n",
    "   \n",
    "\n",
    "    # Run job\n",
    "    ${dep}/hpcSubmit ${job} 01:00:00 3 6Gb\n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"\n",
    "    head ${job}      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4. Use the flowfields to send the images to MNI space\n",
    "\n",
    "This uses smoothing with an 8mm gaussian kernel. This is reasonable...\n",
    "It uses the 'preserve volumes' option, whereby when a voxel is grown/expanded in the move to MNI, its value its reduced  (ie. the concentration of that voxel is modulated).\n",
    "\n",
    "If you need to change these settings edit the script move_to_mni.m and then re run your cell.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "#------------------\n",
    "   \n",
    "template_basename=\"Template\"\n",
    "template=${workingDir}/templates/${template_basename}_6.nii\n",
    "\n",
    "unset files;\n",
    "echo \"\" > ${workingDir}/register2MNI.txt;\n",
    "job=${workingDir}/register2MNI.txt;\n",
    "\n",
    "for subject in `cat ${workingDir}/subj.txt` \n",
    "do\n",
    "\n",
    "         files=\"\"\n",
    "\n",
    "         u_rc1=`ls ${subject}/anat/T1w/u_rc1*_T1w.nii`;\n",
    "         c1=`ls ${subject}/anat/T1w/c1*_T1w.nii`;\n",
    "         c2=`ls ${subject}/anat/T1w/c2*_T1w.nii`;\n",
    "         c3=`ls ${subject}/anat/T1w/c3*_T1w.nii`;\n",
    "\n",
    "         files=\"'${u_rc1}','${c1}','${c2}','${c3}'\";\n",
    "\n",
    "\n",
    "         if [ -f $u_rc1 ];\n",
    "         then\n",
    "\n",
    "          echo \"${dep}/hpcwrapmatlab.sh \\\"move_to_mni('${template}', ${files})\\\"\" >> ${job};\n",
    "\n",
    "        else\n",
    "        echo \"No flowfield for this person ${subject} and timepoint ${session}\";\n",
    "        fi\n",
    "\n",
    "        unset files;\n",
    "\n",
    "done\n",
    "\n",
    "    # Run job\n",
    "    ${dep}/hpcSubmit ${job} 01:00:00 3 6Gb\n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"\n",
    "    head ${job}      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "echo $workingDir\n",
    "${fsl}\n",
    "#----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QC CHECK: Have a look at your MNI space spatially normalised and smoothed Jacobian images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5. Some tract stats in fsl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "${fsl}\n",
    "#----------------\n",
    "\n",
    "dataDir=${workingDir}/volumetric_results\n",
    "mkdir -p ${dataDir}/tractStats\n",
    "tractDIR=~/templates/Corrected_Tracts/\n",
    "\n",
    "# List standard GM\n",
    "echo \"\" > ${workingDir}/smwc1_list.txt\n",
    "\n",
    "for subject in `ls ${workingDir}/data/`\n",
    "    do\n",
    "    for ses in `ls ${workingDir}/data/${subject}/`; \n",
    "        do \n",
    "        ls ${workingDir}/data/${subject}/${ses}/anat/T1w/smwc1*_T1w.nii >> ${workingDir}/smwc1_list.txt\n",
    "    done\n",
    "done\n",
    "    \n",
    "\n",
    "# list standard WM\n",
    "echo \"\" > ${workingDir}/smwc2_list.txt\n",
    "for subject in `ls ${workingDir}/data/`\n",
    "    do\n",
    "    for ses in `ls ${workingDir}/data/${subject}/`; \n",
    "        do \n",
    "        ls ${workingDir}/data/${subject}/${ses}/anat/T1w/smwc2*_T1w.nii >> ${workingDir}/smwc2_list.txt\n",
    "    done\n",
    "done\n",
    "    \n",
    "    \n",
    "fslmerge -t ${dataDir}/all_smwc1 `cat ${workingDir}/smwc1_list.txt`\n",
    "fslmerge -t ${dataDir}/all_smwc2 `cat ${workingDir}/smwc2_list.txt`\n",
    "\n",
    "# create mean GM\n",
    "fslmaths ${dataDir}/all_smwc1 -max 0 -Tmin -bin ${dataDir}/all_smwc1_mask -odt char\n",
    "fslmaths ${dataDir}/all_smwc1 -mas ${dataDir}/all_smwc1_mask ${dataDir}/all_smwc1\n",
    "fslmaths ${dataDir}/all_smwc1 -Tmean ${dataDir}/mean_smwc1\n",
    "fslmaths ${dataDir}/mean_smwc1 -thr 0.5 -bin ${dataDir}/mean_smwc1_mask \n",
    "\n",
    "# create mean WM\n",
    "fslmaths ${dataDir}/all_smwc2 -max 0 -Tmin -bin ${dataDir}/all_smwc2_mask -odt char\n",
    "fslmaths ${dataDir}/all_smwc2 -mas ${dataDir}/all_smwc2_mask ${dataDir}/all_smwc2\n",
    "fslmaths ${dataDir}/all_smwc2 -Tmean ${dataDir}/mean_smwc2\n",
    "fslmaths ${dataDir}/mean_smwc2 -thr 0.5 -bin ${dataDir}/mean_smwc2_mask \n",
    "\n",
    "\n",
    "#Find the tract masks\n",
    "cd ${tractDIR}\n",
    "TRACTS=`ls *.gz`\n",
    "\n",
    "# Nested for loop - for each mask and each metric do fslstats\n",
    "for i in $TRACTS; \n",
    "do\n",
    "    #j=$(echo ${i} | cut -d '_' -f2-)\n",
    "    k=$(echo ${i} | cut -d '.' -f1)\n",
    "    \n",
    "    echo $k > ${dataDir}/tractStats/vol_MNI_${k}.txt\n",
    "    fslstats -t ${dataDir}/all_smwc2.nii.gz -k ${tractDIR}/$i -M >> ${dataDir}/tractStats/vol_MNI_${k}.txt\n",
    "done \n",
    "\n",
    "cp ${workingDir}/smwc2_list.txt ${dataDir}/tractStats/aaa.txt\n",
    "\n",
    "echo \"WM_VOL\" > ${dataDir}/tractStats/vol_MNI_WM.txt\n",
    "fslstats -t ${dataDir}/all_smwc2.nii.gz -k ${dataDir}/mean_smwc2_mask.nii.gz -M >> ${dataDir}/tractStats/vol_MNI_WM.txt\n",
    "echo \"GM_VOL\" > ${dataDir}/tractStats/vol_MNI_GM.txt\n",
    "fslstats -t ${dataDir}/all_smwc1.nii.gz -k ${dataDir}/mean_smwc1_mask.nii.gz -M >> ${dataDir}/tractStats/vol_MNI_GM.txt\n",
    "\n",
    "\n",
    "# paste -d , `ls` >> ../tractStats.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *Remember to copy relevent outputs to derivitives! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional ROIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "${fsl}\n",
    "#----------------\n",
    "\n",
    "dataDir=${workingDir}/volumetric_results\n",
    "mkdir -p ${dataDir}/tractStats\n",
    "tractDIR=~/templates/Corrected_Tracts/\n",
    "\n",
    "\n",
    "#Find the tract masks\n",
    "cd ${tractDIR}\n",
    "TRACTS=`ls *.gz`\n",
    "\n",
    "# Nested for loop - for each mask and each metric do fslstats\n",
    "for i in $TRACTS; \n",
    "do\n",
    "    #j=$(echo ${i} | cut -d '_' -f2-)\n",
    "    k=$(echo ${i} | cut -d '.' -f1)\n",
    "    \n",
    "    echo $k > ${dataDir}/tractStats/vol_MNI_${k}.txt\n",
    "    fslstats -t ${dataDir}/all_smwc2.nii.gz -k ${tractDIR}/$i -M >> ${dataDir}/tractStats/vol_MNI_${k}.txt\n",
    "done \n",
    "\n",
    "cp ${workingDir}/smwc2_list.txt ${dataDir}/tractStats/aaa.txt\n",
    "\n",
    "\n",
    "# paste -d , `ls` >> ../tractStats.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voxelwise analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rds/general/project/c3nl_djs_imaging_data/ephemeral/PTBI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: $PATH does not agree with $PATH_modshare counter. The following directories' usage counters were adjusted to match. Note that this may mean that module unloading may not work correctly.\n",
      " /home/nbourke/anaconda3/envs/py27/bin /apps/gcc/6.2.0/ /opt/ibutils/bin /rds/general/user/nbourke/home/anaconda3/bin /apps/mrtrix/3.0/bin /apps/ants/2015-02-23/bin/bin /apps/gcc/6.2.0/bin /usr/local/sbin /opt/pbs/bin /usr/lib64/qt-3.3/bin /apps/anaconda3/4.5.12/install /apps/ants/2015-02-23/bin/\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "${fsl}\n",
    "#----------------\n",
    "\n",
    "# Update working dir, as done after main analysis was conducted\n",
    "wd=/rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds\n",
    "\n",
    "# Remove pilot\n",
    "fslmerge -t ${wd}/derivatives/volumetric_results/all_smwc1 `cat ${wd}/derivatives/volumetric_results/smwc1_list.txt`\n",
    "fslmerge -t ${wd}/derivatives/volumetric_results/all_smwc2 `cat ${wd}/derivatives/volumetric_results/smwc2_list.txt`\n",
    "\n",
    "# design=${scriptDir}/scripts/design/demo.mat\n",
    "# contrast=${scriptDir}/scripts/design/mainContrast.con \n",
    "# setup_masks ${design} ${contrast} ${scriptDir}/scripts/design/${ii} `cat ${scriptDir}/scripts/design/masks.txt` \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rds/general/project/c3nl_djs_imaging_data/ephemeral/PTBI\n",
      "MATRIX SIZE IS 59 3\n",
      "/apps/fsl/6.0.1/fsl/bin/fslmerge -t /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/scripts/design/MNIlesion /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF1638_ses-2017-03-30-PTBI001_contusion_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF1702_ses-2017-05-31-PTBI003_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF1703_ses-2017-05-31-PTBI101_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF1704_ses-2017-06-01-PTBI002_contusion_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF1705_ses-2017-06-01-PTBI102v1_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF1724_ses-2017-06-23-PTBi103_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF1732_ses-2017-07-04-PTBi004_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF1733_ses-2017-07-04-PTBI104_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF1783_ses-2017-08-14-PTBI_005_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF1803_ses-2017-09-18-PTBI_007_contusion_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF1847_ses-2017-10-24-PTBI_009_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF1848_ses-2017-10-24-PTBI_105_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF1849_ses-2017-10-24-PITB_010_contusion_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF1864_ses-2017-11-08-PTBI_012_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF1870_ses-2017-11-20-PTBI_011_contusion_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF1893_ses-2017-12-18-PTBI_106_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF1894_ses-2017-12-19-PTBI_013_contusion_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF1895_ses-2017-12-19-PTBI_108_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF1896_ses-2017-12-19-PTBI_107_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF1937_ses-2018-02-13-PTBI_109_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF1943_ses-2018-02-14-PTBI_015_contusion_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF1944_ses-2018-02-15-PTBI_016_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF1946_ses-2018-02-15-PTBI_017_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2010_ses-2018-03-22-PTBI_018_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2024_ses-2018-03-28-PTBI_110_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2044_ses-2018-04-10-PTBI_111_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2045_ses-2018-04-10-PTBI_112_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2051_ses-2018-04-12-PTBI019_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2053_ses-2018-04-12-PTBI113_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2131_ses-2018-05-22-PTBI_021_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2140_ses-2018-05-30-PTBI_114_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2141_ses-2018-05-30-PTBI022_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2145_ses-2018-06-01-PTBI_023_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2147_ses-2018-06-01-PTBI_115_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2155_ses-2018-06-14-PTBI_024_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2162_ses-2018-06-20-PTBI_025_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2166_ses-2018-06-22-PTBI_026_contusion_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2170_ses-2018-06-28-PTBI_028_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2171_ses-2018-06-28-PTBI_117_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2178_ses-2018-07-10-PTBI_029_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2179_ses-2018-07-10-PTBI_020_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2189_ses-2018-07-23-PTBI_118_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2206_ses-2018-08-13-PTBI030_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2222_ses-2018-08-20-PTBI027_Pt1_contusion_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2223_ses-2018-08-20-PTBI116_Pt1_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2258_ses-2018-09-11-PTBI_032_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2275_ses-2018-09-24-PTBI_119_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2276_ses-2018-09-24-PTBI_033_contusion_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2300_ses-2018-10-08-AMR_PTBI031_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2330_ses-2018-10-23-PTBI_120_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2331_ses-2018-10-23-PTBI_034_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2332_ses-2018-10-23-PTBI_035_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2345_ses-2018-10-25-PTBI_036_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2392_ses-2018-11-09-PTBI_121_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2411_ses-2018-11-15-PTBI_038_contusion_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2438_ses-2018-11-22-PTBI_040_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2439_ses-2018-11-22-PTBI_039_empty_mask_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2440_ses-2018-11-22-PTBI_041_contusion_MNI.nii.gz /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/lesionMasks/MNI/bin_sub-CIF2446_ses-2018-11-26-PTBI_037_contusion_MNI.nii.gz\n",
      "Example randomise call:\n",
      "  randomise -i <input> -o <output> -d /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/scripts/design/MNIlesion.mat -t /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/scripts/design/MNIlesion.con --vxl=-4 --vxf=/rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/scripts/design/MNIlesion [other options]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: $PATH does not agree with $PATH_modshare counter. The following directories' usage counters were adjusted to match. Note that this may mean that module unloading may not work correctly.\n",
      " /home/nbourke/anaconda3/envs/py27/bin /apps/gcc/6.2.0/ /opt/ibutils/bin /rds/general/user/nbourke/home/anaconda3/bin /apps/mrtrix/3.0/bin /apps/ants/2015-02-23/bin/bin /apps/gcc/6.2.0/bin /usr/local/sbin /opt/pbs/bin /usr/lib64/qt-3.3/bin /apps/anaconda3/4.5.12/install /apps/ants/2015-02-23/bin/\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "module load fsl/6.0.1/\n",
    "#----------------------------\n",
    "\n",
    "wd=/rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds\n",
    "design=${wd}/scripts/design/demo.mat\n",
    "contrast=${wd}/scripts/design/mainContrast.con\n",
    "\n",
    "# Run setup masks command\n",
    "setup_masks ${design} ${contrast} ${wd}/scripts/design/MNIlesion `ls ${wd}/derivatives/lesionMasks/MNI/bin*`   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rds/general/project/c3nl_djs_imaging_data/ephemeral/PTBI\n",
      " Walltime = 24:00:00 \n",
      " Mem = 14Gb \n",
      "Randomise Input: -i /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/volumetric_results/all_smwc1.nii.gz -o /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/tbss_lesion_output//smwc1/smwc1_TBSS -m /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/volumetric_results/mean_smwc1_mask.nii.gz -d /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/scripts/design/MNIlesion.mat -t /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/scripts/design/MNIlesion.con --vxl=-4 --vxf=/rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/scripts/design/MNIlesion.nii.gz -n 5000 --T2 -V\n",
      "RANDOMISE_OUTPUT: 5000 4 /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/tbss_lesion_output//smwc1/smwc1_TBSS 100\n",
      "\n",
      "Dirname is: /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/tbss_lesion_output//smwc1\n",
      "Generating 200 fragments for  4  contrasts with  100 permutations per fragment. Allocating minutes per fragment.\n",
      "The total number of permutations per contrast will be 5000 .\n",
      "done 1\n",
      "done 2\n",
      "done 3\n",
      "done 4\n",
      "done 5\n",
      "done 6\n",
      "done 7\n",
      "done 8\n",
      "done 9\n",
      "done 10\n",
      "done 11\n",
      "done 12\n",
      "done 13\n",
      "done 14\n",
      "done 15\n",
      "done 16\n",
      "done 17\n",
      "done 18\n",
      "done 19\n",
      "done 20\n",
      "done 21\n",
      "done 22\n",
      "done 23\n",
      "done 24\n",
      "done 25\n",
      "done 26\n",
      "done 27\n",
      "done 28\n",
      "done 29\n",
      "done 30\n",
      "done 31\n",
      "done 32\n",
      "done 33\n",
      "done 34\n",
      "done 35\n",
      "done 36\n",
      "done 37\n",
      "done 38\n",
      "done 39\n",
      "done 40\n",
      "done 41\n",
      "done 42\n",
      "done 43\n",
      "done 44\n",
      "done 45\n",
      "done 46\n",
      "done 47\n",
      "done 48\n",
      "done 49\n",
      "done 50\n",
      "******\n",
      "pbsfile is /rds/general/ephemeral/user/nbourke/ephemeral/tmp.3qpJyAz1HS\n",
      "#!/bin/sh\n",
      "#PBS -l walltime=24:00:00\n",
      "#PBS -l select=1:ncpus=1:mem=14Gb\n",
      "#PBS -J 1-200\n",
      "cmd=`sed \"${PBS_ARRAY_INDEX}q;d\" /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/tbss_lesion_output//smwc1/smwc1_TBSS.generate`\n",
      "${cmd}\n",
      "******\n",
      "\n",
      "******\n",
      "pbsfile_depend is: \n",
      "#!/bin/sh\n",
      "#PBS -l walltime=02:00:00\n",
      "#PBS -l select=1:ncpus=1:mem=8Gb\n",
      "#PBS -W depend=afterok:1636286[].pbs\n",
      "/rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/tbss_lesion_output//smwc1/smwc1_TBSS.defragment\n",
      "******\n",
      "1636287.pbs\n",
      " Walltime = 24:00:00 \n",
      " Mem = 14Gb \n",
      "Randomise Input: -i /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/volumetric_results/all_smwc2.nii.gz -o /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/tbss_lesion_output//smwc2/smwc2_TBSS -m /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/derivatives/volumetric_results/mean_smwc2_mask.nii.gz -d /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/scripts/design/MNIlesion.mat -t /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/scripts/design/MNIlesion.con --vxl=-4 --vxf=/rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/scripts/design/MNIlesion.nii.gz -n 5000 --T2 -V\n",
      "RANDOMISE_OUTPUT: 5000 4 /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/tbss_lesion_output//smwc2/smwc2_TBSS 100\n",
      "\n",
      "Dirname is: /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/tbss_lesion_output//smwc2\n",
      "Generating 200 fragments for  4  contrasts with  100 permutations per fragment. Allocating minutes per fragment.\n",
      "The total number of permutations per contrast will be 5000 .\n",
      "done 1\n",
      "done 2\n",
      "done 3\n",
      "done 4\n",
      "done 5\n",
      "done 6\n",
      "done 7\n",
      "done 8\n",
      "done 9\n",
      "done 10\n",
      "done 11\n",
      "done 12\n",
      "done 13\n",
      "done 14\n",
      "done 15\n",
      "done 16\n",
      "done 17\n",
      "done 18\n",
      "done 19\n",
      "done 20\n",
      "done 21\n",
      "done 22\n",
      "done 23\n",
      "done 24\n",
      "done 25\n",
      "done 26\n",
      "done 27\n",
      "done 28\n",
      "done 29\n",
      "done 30\n",
      "done 31\n",
      "done 32\n",
      "done 33\n",
      "done 34\n",
      "done 35\n",
      "done 36\n",
      "done 37\n",
      "done 38\n",
      "done 39\n",
      "done 40\n",
      "done 41\n",
      "done 42\n",
      "done 43\n",
      "done 44\n",
      "done 45\n",
      "done 46\n",
      "done 47\n",
      "done 48\n",
      "done 49\n",
      "done 50\n",
      "******\n",
      "pbsfile is /rds/general/ephemeral/user/nbourke/ephemeral/tmp.LGxFw2KoY8\n",
      "#!/bin/sh\n",
      "#PBS -l walltime=24:00:00\n",
      "#PBS -l select=1:ncpus=1:mem=14Gb\n",
      "#PBS -J 1-200\n",
      "cmd=`sed \"${PBS_ARRAY_INDEX}q;d\" /rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/tbss_lesion_output//smwc2/smwc2_TBSS.generate`\n",
      "${cmd}\n",
      "******\n",
      "\n",
      "******\n",
      "pbsfile_depend is: \n",
      "#!/bin/sh\n",
      "#PBS -l walltime=02:00:00\n",
      "#PBS -l select=1:ncpus=1:mem=8Gb\n",
      "#PBS -W depend=afterok:1636288[].pbs\n",
      "/rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds/tbss_lesion_output//smwc2/smwc2_TBSS.defragment\n",
      "******\n",
      "1636289.pbs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: $PATH does not agree with $PATH_modshare counter. The following directories' usage counters were adjusted to match. Note that this may mean that module unloading may not work correctly.\n",
      " /home/nbourke/anaconda3/envs/py27/bin /apps/gcc/6.2.0/ /opt/ibutils/bin /rds/general/user/nbourke/home/anaconda3/bin /apps/mrtrix/3.0/bin /apps/ants/2015-02-23/bin/bin /apps/gcc/6.2.0/bin /usr/local/sbin /opt/pbs/bin /usr/lib64/qt-3.3/bin /apps/anaconda3/4.5.12/install /apps/ants/2015-02-23/bin/\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "module load fsl/6.0.1/\n",
    "#----------------------------\n",
    "\n",
    "# Update working dir, as done after main analysis was conducted\n",
    "wd=/rds/general/project/c3nl_djs_imaging_data/live/analysis/paeds\n",
    "output=${wd}/tbss_lesion_output/\n",
    "\n",
    "# Remove pilot\n",
    "# fslmerge -t ${wd}/derivatives/volumetric_results/all_smwc1 `cat ${wd}/derivatives/volumetric_results/smwc1_list.txt`\n",
    "# fslmerge -t ${wd}/derivatives/volumetric_results/all_smwc2 `cat ${wd}/derivatives/volumetric_results/smwc2_list.txt`\n",
    "\n",
    "for ii in smwc1 smwc2\n",
    "    do\n",
    "    data_input=${wd}/derivatives/volumetric_results/all_${ii}.nii.gz\n",
    "    data_mask=${wd}/derivatives/volumetric_results/mean_${ii}_mask.nii.gz\n",
    "    design=${wd}/scripts/design/MNIlesion.mat\n",
    "    contrast=${wd}/scripts/design/MNIlesion.con\n",
    "    basename=${wd}/scripts/design/MNIlesion.nii.gz\n",
    "    \n",
    "    mkdir ${output}/${ii}\n",
    "    ## Run command ##\n",
    "    ${dep}/pbs_randomise_par -wt 24:00:00 -mem 14Gb -i ${data_input} -o ${output}/${ii}/${ii}_TBSS -m ${data_mask} -d ${design} -t ${contrast} --vxl=-4 --vxf=${basename} -n 5000 --T2 -V  \n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Freesurfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rds/general/project/c3nl_djs_imaging_data/ephemeral/PTBI\n",
      "input is = /rds/general/project/c3nl_djs_imaging_data/ephemeral/PTBI/PTBI_fs_job.txt\n",
      "Walltime = 20:00:00\n",
      "Number of CPUs = 1\n",
      "Memory = 12Gb\n",
      "Array jobs submitted: 2\n",
      "Job submitted: Fri 15 May 13:31:09 BST 2020\n",
      "1530903[].pbs\n",
      "\n",
      "***\n",
      "\n",
      "Submitted commands:\n",
      "/rds/general/user/nbourke/home/group_paeds/scripts/pbsFreesurfer -i sub-CIF1703 ses-2017-05-31-PTBI101 /rds/general/project/c3nl_djs_imaging_data/ephemeral/PTBI\n",
      "/rds/general/user/nbourke/home/group_paeds/scripts/pbsFreesurfer -i sub-CIF2178 ses-2018-07-10-PTBI_029 /rds/general/project/c3nl_djs_imaging_data/ephemeral/PTBI\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: $PATH does not agree with $PATH_modshare counter. The following directories' usage counters were adjusted to match. Note that this may mean that module unloading may not work correctly.\n",
      " /home/nbourke/anaconda3/envs/py27/bin /apps/gcc/6.2.0/ /opt/ibutils/bin /rds/general/user/nbourke/home/anaconda3/bin /apps/mrtrix/3.0/bin /apps/ants/2015-02-23/bin/bin /apps/gcc/6.2.0/bin /usr/local/sbin /opt/pbs/bin /usr/lib64/qt-3.3/bin /apps/anaconda3/4.5.12/install /apps/ants/2015-02-23/bin/\n",
      "rm: cannot remove ‘/rds/general/project/c3nl_djs_imaging_data/ephemeral/PTBI/data/sub-CIF1703/ses-2017-05-31-PTBI101/anat/T1w/fs’: No such file or directory\n",
      "rm: cannot remove ‘/rds/general/project/c3nl_djs_imaging_data/ephemeral/PTBI/data/sub-CIF1703/ses-2017-05-31-PTBI101/anat/T1w/fsaverage’: No such file or directory\n",
      "rm: cannot remove ‘/rds/general/project/c3nl_djs_imaging_data/ephemeral/PTBI/data/sub-CIF2178/ses-2018-07-10-PTBI_029/anat/T1w/fs’: No such file or directory\n",
      "rm: cannot remove ‘/rds/general/project/c3nl_djs_imaging_data/ephemeral/PTBI/data/sub-CIF2178/ses-2018-07-10-PTBI_029/anat/T1w/fsaverage’: No such file or directory\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "\n",
    "module load fsl\n",
    "#----------------------------\n",
    "\n",
    "# Set job command File \n",
    "echo -n \"\" > ${workingDir}/${project}_fs_job.txt\n",
    "job=${workingDir}/${project}_fs_job.txt\n",
    "\n",
    "\n",
    "### Job loop ###\n",
    "for subject in sub-CIF1703 sub-CIF2178 #`ls ${workingDir}/data/`\n",
    "    do\n",
    "    for ses in `ls ${workingDir}/data/${subject}/`; \n",
    "        do \n",
    "        rm -r ${workingDir}/data/${subject}/${ses}/anat/T1w/fs\n",
    "        rm -r ${workingDir}/data/${subject}/${ses}/anat/T1w/fsaverage\n",
    "        rm -r ${workingDir}/data/${subject}/${ses}/anat/T1w/T1w\n",
    "        echo \"/rds/general/user/nbourke/home/group_paeds/scripts/pbsFreesurfer -i ${subject} ${ses} ${workingDir}\" >> ${job}           \n",
    "    done\n",
    "done\n",
    "\n",
    "    # Run job\n",
    "    ${dep}/hpcSubmit ${job} 20:00:00 1 12Gb\n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"\n",
    "    head ${job}\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *The following aparcstats2table command works when copied into the terminal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "\n",
    "module load fsl\n",
    "module load freesurfer\n",
    "#----------------------------\n",
    "EXPERIMENT_DIR=${workingDir}\n",
    "export SUBJECTS_DIR=`${workingDir}/data/`\n",
    "\n",
    "\n",
    "counter=1\n",
    "### Job loop ###\n",
    "for subject in `ls ${workingDir}/data/`\n",
    "    do\n",
    "    for ses in `ls ${workingDir}/data/${subject}/`; \n",
    "        do  \n",
    "        echo -e \"$( if [ \"${counter}\" -eq \"1\" ]; then echo \"First run: \"; fi )${subject}\"\n",
    "\n",
    "        \n",
    "        XX=${workingDir}/data/${subject}/${ses}/anat/T1w/fs \n",
    "        #Thickness\n",
    "        aparcstats2table --subjects $XX --hemi rh --meas thickness  --tablefile ${workingDir}/data/${subject}/${ses}/anat/T1w/fs/rh_thick_aparc_stats.txt\n",
    "        aparcstats2table --subjects $XX --hemi lh --meas thickness  --tablefile ${workingDir}/data/${subject}/${ses}/anat/T1w/fs/lh_thick_aparc_stats.txt\n",
    "        # Volume\n",
    "        aparcstats2table --subjects $XX --hemi rh --meas volume --tablefile ${workingDir}/data/${subject}/${ses}/anat/T1w/fs/rh_vol_aparc_stats.txt\n",
    "        aparcstats2table --subjects $XX --hemi lh --meas volume --tablefile ${workingDir}/data/${subject}/${ses}/anat/T1w/fs/lh_vol_aparc_stats.txt\n",
    "        \n",
    "        \n",
    "    done\n",
    "    counter=$((counter +1))\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting FreeSurfer measurments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "\n",
    "#----------------------------\n",
    "\n",
    "echo \"\" > ${workingDir}/rh_thick_aparc_stats.txt\n",
    "echo \"\" > ${workingDir}/lh_thick_aparc_stats.txt\n",
    "echo \"\" > ${workingDir}/rh_vol_aparc_stats.txt\n",
    "echo \"\" > ${workingDir}/lh_vol_aparc_stats.txt\n",
    "\n",
    "counter=1\n",
    "### Job loop ###\n",
    "for subject in `ls ${workingDir}/data/`\n",
    "    do\n",
    "    for ses in `ls ${workingDir}/data/${subject}/`; \n",
    "        do  \n",
    "        XX=${workingDir}/data/${subject}/${ses}/anat/T1w/fs\n",
    "        \n",
    "        echo -e \"$( if [ \"${counter}\" -eq \"10\" ]; then sed '1q;d' ${XX}/rh_thick_aparc_stats.txt >> ${workingDir}/rh_thick_aparc_stats.txt; sed '1q;d' ${XX}/lh_thick_aparc_stats.txt >> ${workingDir}/lh_thick_aparc_stats.txt; sed '1q;d' ${XX}/rh_vol_aparc_stats.txt >> ${workingDir}/rh_vol_aparc_stats.txt; sed '1q;d' ${XX}/lh_vol_aparc_stats.txt >> ${workingDir}/lh_vol_aparc_stats.txt; fi )\"  \n",
    " \n",
    "        sed '2q;d' ${XX}/rh_thick_aparc_stats.txt >> ${workingDir}/rh_thick_aparc_stats.txt\n",
    "        sed '2q;d' ${XX}/lh_thick_aparc_stats.txt >> ${workingDir}/lh_thick_aparc_stats.txt\n",
    "        sed '2q;d' ${XX}/rh_vol_aparc_stats.txt >> ${workingDir}/rh_vol_aparc_stats.txt\n",
    "        sed '2q;d' ${XX}/lh_vol_aparc_stats.txt >> ${workingDir}/lh_vol_aparc_stats.txt\n",
    "\n",
    "    done\n",
    "    counter=$((counter +1))\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. mv to local\n",
    "2. open in excell\n",
    "3. correct heading\n",
    "4. save as csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Registering lesion masks to MNI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rds/general/project/c3nl_djs_imaging_data/ephemeral/PTBI\n",
      "ses-2017-03-27-PILOT_AMR does not have a lesion, making empty mask file\n",
      "ses-2017-03-30-PTBI001 has a lesion\n",
      "ses-2017-05-31-PTBI003 does not have a lesion, making empty mask file\n",
      "ses-2017-05-31-PTBI101 does not have a lesion, making empty mask file\n",
      "ses-2017-06-01-PTBI002 has a lesion\n",
      "ses-2017-06-01-PTBI102v1 does not have a lesion, making empty mask file\n",
      "ses-2017-06-23-PTBi103 does not have a lesion, making empty mask file\n",
      "ses-2017-07-04-PTBi004 does not have a lesion, making empty mask file\n",
      "ses-2017-07-04-PTBI104 does not have a lesion, making empty mask file\n",
      "ses-2017-08-14-PTBI_005 does not have a lesion, making empty mask file\n",
      "ses-2017-09-18-PTBI_007 has a lesion\n",
      "ses-2017-10-24-PTBI_009 does not have a lesion, making empty mask file\n",
      "ses-2017-10-24-PTBI_105 does not have a lesion, making empty mask file\n",
      "ses-2017-10-24-PITB_010 has a lesion\n",
      "ses-2017-11-08-PTBI_012 does not have a lesion, making empty mask file\n",
      "ses-2017-11-20-PTBI_011 has a lesion\n",
      "ses-2017-12-18-PTBI_106 does not have a lesion, making empty mask file\n",
      "ses-2017-12-19-PTBI_013 has a lesion\n",
      "ses-2017-12-19-PTBI_108 does not have a lesion, making empty mask file\n",
      "ses-2017-12-19-PTBI_107 does not have a lesion, making empty mask file\n",
      "ses-2018-02-13-PTBI_109 does not have a lesion, making empty mask file\n",
      "ses-2018-02-14-PTBI_015 has a lesion\n",
      "ses-2018-02-15-PTBI_016 does not have a lesion, making empty mask file\n",
      "ses-2018-02-15-PTBI_017 does not have a lesion, making empty mask file\n",
      "ses-2018-03-22-PTBI_018 does not have a lesion, making empty mask file\n",
      "ses-2018-03-28-PTBI_110 does not have a lesion, making empty mask file\n",
      "ses-2018-04-10-PTBI_111 does not have a lesion, making empty mask file\n",
      "ses-2018-04-10-PTBI_112 does not have a lesion, making empty mask file\n",
      "ses-2018-04-12-PTBI019 does not have a lesion, making empty mask file\n",
      "ses-2018-04-12-PTBI113 does not have a lesion, making empty mask file\n",
      "ses-2018-05-22-PTBI_021 does not have a lesion, making empty mask file\n",
      "ses-2018-05-30-PTBI_114 does not have a lesion, making empty mask file\n",
      "ses-2018-05-30-PTBI022 does not have a lesion, making empty mask file\n",
      "ses-2018-06-01-PTBI_023 does not have a lesion, making empty mask file\n",
      "ses-2018-06-01-PTBI_115 does not have a lesion, making empty mask file\n",
      "ses-2018-06-14-PTBI_024 does not have a lesion, making empty mask file\n",
      "ses-2018-06-20-PTBI_025 does not have a lesion, making empty mask file\n",
      "ses-2018-06-22-PTBI_026 has a lesion\n",
      "ses-2018-06-28-PTBI_028 does not have a lesion, making empty mask file\n",
      "ses-2018-06-28-PTBI_117 does not have a lesion, making empty mask file\n",
      "ses-2018-07-10-PTBI_029 does not have a lesion, making empty mask file\n",
      "ses-2018-07-10-PTBI_020 does not have a lesion, making empty mask file\n",
      "ses-2018-07-23-PTBI_118 does not have a lesion, making empty mask file\n",
      "ses-2018-08-13-PTBI030 does not have a lesion, making empty mask file\n",
      "ses-2018-08-20-PTBI027_Pt1 has a lesion\n",
      "ses-2018-08-20-PTBI116_Pt1 does not have a lesion, making empty mask file\n",
      "ses-2018-09-11-PTBI_032 does not have a lesion, making empty mask file\n",
      "ses-2018-09-24-PTBI_119 does not have a lesion, making empty mask file\n",
      "ses-2018-09-24-PTBI_033 has a lesion\n",
      "ses-2018-10-08-AMR_PTBI031 does not have a lesion, making empty mask file\n",
      "ses-2018-10-23-PTBI_120 does not have a lesion, making empty mask file\n",
      "ses-2018-10-23-PTBI_034 does not have a lesion, making empty mask file\n",
      "ses-2018-10-23-PTBI_035 does not have a lesion, making empty mask file\n",
      "ses-2018-10-25-PTBI_036 does not have a lesion, making empty mask file\n",
      "ses-2018-11-09-PTBI_121 does not have a lesion, making empty mask file\n",
      "ses-2018-11-15-PTBI_038 has a lesion\n",
      "ses-2018-11-22-PTBI_040 does not have a lesion, making empty mask file\n",
      "ses-2018-11-22-PTBI_039 does not have a lesion, making empty mask file\n",
      "ses-2018-11-22-PTBI_041 has a lesion\n",
      "ses-2018-11-26-PTBI_037 has a lesion\n",
      "\n",
      "***\n",
      "\n",
      "Submitted commands:\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘/rds/general/project/c3nl_djs_imaging_data/ephemeral/PTBI/tmpReg’: File exists\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source ${setup}\n",
    "echo ${workingDir}\n",
    "\n",
    "#----------------------------\n",
    "\n",
    "echo \"\" > ${workingDir}/commandLogs/lesion_reg.txt\n",
    "job=${workingDir}/commandLogs/lesion_reg.txt\n",
    "mkdir ${workingDir}/tmpReg\n",
    "### Job loop ###\n",
    "for subject in `ls ${workingDir}/data/`\n",
    "    do\n",
    "    for ses in `ls ${workingDir}/data/${subject}/`; \n",
    "        do  \n",
    "        brain=${workingDir}/data/${subject}/${ses}/anat/T1w/${subject}_${ses}_T1w_brain.nii.gz  \n",
    "        lesion=${workingDir}/lesionMasks/${subject}_${ses}_contusion.nii.gz\n",
    "        \n",
    "        if [ -f \"$lesion\" ]; then\n",
    "            echo \"$ses has a lesion\"\n",
    "            echo \"${fsl}; flirt -in ${brain} -ref /rds/general/apps/fsl/5.0.10/install/data/standard/MNI152_T1_1mm_brain.nii.gz -omat ${workingDir}/tmpReg/${subject}_${ses}_T1brain2MNI.mat -dof 6 -cost mutualinfo -searchcost mutualinfo; flirt -in ${lesion} -ref /rds/general/apps/fsl/5.0.10/install/data/standard/MNI152_T1_1mm_brain.nii.gz -applyxfm -init ${workingDir}/tmpReg/${subject}_${ses}_T1brain2MNI.mat -out ${workingDir}/lesionMasks/MNI/${subject}_${ses}_contusion_MNI.nii.gz\" >> ${job}  \n",
    "        else\n",
    "            echo \"$ses does not have a lesion, making empty mask file\"\n",
    "            cp /rds/general/user/nbourke/home/templates/MNI152_T1_1mm_empty_mask.nii ${workingDir}/lesionMasks/MNI/${subject}_${ses}_empty_mask_MNI.nii.gz\n",
    "        fi\n",
    "    done\n",
    "done\n",
    "\n",
    "    # Run job\n",
    "    ${dep}/hpcSubmit ${job} 08:00:00 1 12Gb\n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"\n",
    "    head ${job}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
