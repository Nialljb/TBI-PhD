{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked-ICA pipeline\n",
    "Niall Bourke ~ April 2019  \n",
    "Based on Sara's paper https://academic.oup.com/brain/article/141/1/148/4654726\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If doing batch processing with output that may be usful to others -> direct to c3nl_processed in sub dir.\n",
    "#### The first HCP pre-processing steps shouldnt have to be repeated and the pipeline can begin from mICA.\n",
    "#### * Do not write to original HCP directories!!   \n",
    "  \n",
    "---------\n",
    "\n",
    "### Steps:\n",
    "#### 1. Set environment\n",
    "#### 2. HCP pre-processing\n",
    "#### 3. mICA for HCP data (add mask of interest)\n",
    "#### 4. Pre-processing of test data\n",
    "#### 5. Applying network masks from HCP to test data\n",
    "\n",
    "\n",
    "\n",
    "### Overview: \n",
    "You want to create your components with unsmoothed independent data (using an anatomical mask of interest). For this we will use the Human Connectome Projects 100 unrelated subjects. After selecting our components we will run out stats on our test data using smoothed data. \n",
    "\n",
    "##### Two data sets\n",
    "1. Independant control group from the HCP to create functional connectivity components\n",
    "2. Test set containing two groups of controls and paitents\n",
    "\n",
    "*These datasets will be treated slightly differently. The components should be dervived from unsmoothed data while the test set should have fully processed and smoothed stata ready for statistics. \n",
    "\n",
    "##### Independant set:\n",
    "    1. subject level melodic\n",
    "    2. mICA preprocessing\n",
    "    3. Group ICA\n",
    "    3. Component selection\n",
    "\n",
    "##### Test set:\n",
    "    1. Single subject melodic\n",
    "    2. QA: framwise displacement (before ICA-AROMA) with a threshold\n",
    "    3. Fix/ICA-AROMA\n",
    "       With Fix/manual do all cleaning first time round. Alternatvily if running ICA AROMA do first level feat without temporal filtering - check documentation - ICA-AROMA will produce a text file with  suggested labels for noise/components. This needs to be reviewed and edited where necessary and then fed back into the second stage. \n",
    "    4. Dual regression on grey matter using network mask (can also included motion regressors)\n",
    "\n",
    "\n",
    "##### Network analysis\n",
    "* When the components have been got - do a dual regression selecting significant regions constrained to GM\n",
    "Remove components that are noise or have high overlap with other components (quant approach)\n",
    "\n",
    "\n",
    "* To process your own data do;\n",
    "single subject melodic , then fix\n",
    "\n",
    "* randomise stage\n",
    "dual regression script and add network mask created from using a component to do whole brain connectivity.  \n",
    "\n",
    "* reproducibility analysis \n",
    "* crib sheet for ICA (kelly, 2008)\n",
    "* fslreg_filt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial setup\n",
    "Bash variables dont carry across cells anymore. Here I have saved them to a text file, which can then be read at the start of a cell. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "project = \"caudalACC\" # \"rostalACC\" # \"lesion\"   \n",
    "\n",
    "directory = (\"/rds/general/user/nbourke/ephemeral/\" + project)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "    \n",
    "raw = (\"/rds/general/project/c3nl_djs_imaging_data/live/data/raw/\" + project + \"/\")\n",
    "source = (\"/rds/general/project/c3nl_djs_imaging_data/live/data/sourcedata/\")\n",
    "workingDir = (\"/rds/general/user/nbourke/ephemeral/mica/\" + project )\n",
    "setup = (workingDir + \"/setup.sh\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can the above set variables in python be exported to bash file below??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /rds/general/user/nbourke/ephemeral/mica/caudalACC/setup.sh\n"
     ]
    }
   ],
   "source": [
    "%%writefile $setup\n",
    "\n",
    "$(: Project label) \n",
    "project=\"caudalACC\" # \"rostalACC\" # \"lesion\" \n",
    "\n",
    "$(:  Where is the RAW directory?)\n",
    "export rawDir=/rds/general/user/nbourke/home/projects/${project}/raw;\n",
    "export testSubjects=/rds/general/user/nbourke/home/projects/${project}/scripts/rawSubj.txt\n",
    "\n",
    "$(: dependencies)\n",
    "export dep=/rds/general/project/c3nl_shared/live/dependencies/\n",
    "export templates=/rds/general/user/nbourke/home/templates\n",
    "export workingDir=/rds/general/user/nbourke/ephemeral/mica/${project}\n",
    "\n",
    "$(: HCP paths)\n",
    "export hcpDir=/rds/general/project/c3nl_djs_imaging_data/live/HCP100\n",
    "export subjects=/rds/general/project/c3nl_djs_imaging_data/live/HCP100/subj.txt\n",
    "\n",
    "\n",
    "# Define modules    \n",
    "fsl=\"module load fsl\";\n",
    "micaEx=\"export MICADIR=/rds/general/project/c3nl_shared/live/dependencies/mICA_Toolbox\";\n",
    "micaDir=/rds/general/project/c3nl_shared/live/dependencies/mICA_Toolbox;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rds/general/user/nbourke/ephemeral/mica/caudalACC\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "echo $workingDir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep the HCP data for analysis\n",
    "\n",
    "* Functional is already in MNI 2mm space  \n",
    "* Skull strip T1 (Done in HCP pipeline)\n",
    "* Register T1_brain to MNI2mm space\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick look over the dimensions of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "echo $workingDir\n",
    "\n",
    "module load fsl\n",
    "module load mrtrix \n",
    "#----------------------------\n",
    "\n",
    "\n",
    "## Loop over all subjects ##\n",
    "for subj in 100307; #`cat $subjects`;\n",
    "do \n",
    "    ## Set data to process ##\n",
    "    T1=${hcpDir}/struct/${subj}/T1w/T1w_acpc_dc_restore.nii.gz\n",
    "    T1Brain=${hcpDir}/struct/${subj}/T1w/T1w_acpc_dc_restore_brain.nii.gz\n",
    "    restClean=${hcpDir}/rest/${subj}/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR_hp2000_clean.nii.gz\n",
    "    \n",
    "    T1_2mm=struct/100307/MNINonLinear/T1w_restore.2.nii.gz\n",
    "    \n",
    "    template=/apps/fsl/5.0.10/fsl/data/standard/MNI152_T1_2mm_brain.nii.gz\n",
    "    \n",
    "    echo \"Looking at the data\"\n",
    "    echo \"\"\n",
    "    echo \"T1 is $T1\"\n",
    "    mrinfo $T1\n",
    "    echo \"Brain is $T1Brain\"\n",
    "    mrinfo $T1Brain\n",
    "    echo \"rest is $restClean\"\n",
    "    mrinfo $restClean\n",
    "    echo \"template is $template\"\n",
    "    mrinfo $template\n",
    "    \n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The HCP has the resting data in MNI2mm space along with the T1. The T1_brain however needs to be registered to the same space. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "echo $workingDir\n",
    "\n",
    "module load fsl\n",
    "#----------------------------\n",
    "\n",
    "hcpDir=/rds/general/project/c3nl_djs_imaging_data/live/HCP100\n",
    "subjects=${hcpDir}/subj.txt\n",
    "mkdir -p ${EPHEMERAL}/mica\n",
    "workingDir=${EPHEMERAL}/mica\n",
    "\n",
    "module load fsl\n",
    "\n",
    "## Set empty Command File ##\n",
    "echo \"\" > ${workingDir}/HCP_Reg_job.txt\n",
    "\n",
    "## Loop over all subjects ##\n",
    "for subj in `cat $subjects`;\n",
    "do \n",
    "    ## Set data to process ##\n",
    "    #T1=${hcpDir}/struct/${subj}/T1w/T1w_acpc_dc_restore.nii.gz\n",
    "    T1Brain=${hcpDir}/struct/${subj}/T1w/T1w_acpc_dc_restore_brain.nii.gz\n",
    "    #restClean=${hcpRest}/${subj}/${subj}.nii.gz\n",
    "    template=/apps/fsl/5.0.10/fsl/data/standard/MNI152_T1_2mm_brain.nii.gz\n",
    "   \n",
    "    # Only need to register T1_brain to 2mm space\n",
    "    echo \"module load fsl; flirt -in ${T1Brain} -ref ${template} -out ${hcpDir}/struct/${subj}/T1w/MNI152_2mm_T1w_acpc_dc_restore_brain.nii.gz;\" >> ${workingDir}/HCP_Reg_job.txt\n",
    "done\n",
    "\n",
    "## Run jobs ## \n",
    "\n",
    "    /rds/general/project/c3nl_shared/live/dependencies/hpcSubmit ${workingDir}/HCP_Reg_job.txt 01:00:00 1 8Gb\n",
    "    # 1. submission command, 2. jobFile, 3. Requested time, 4. number of cpus, 5. ammount of RAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Masked ICA toolbox\n",
    "\n",
    "This is in the dependency folder on the cluster but is has sparse documentation. It uses fsl native commands such as melodic. \n",
    "    \n",
    "* Initially this can just be run through the gui on one subject to make sure its doing what you want (locally not on cluster). When it is running the command output will be printed to the screen. This can be taken and adjusted to batch run a load of subjects.\n",
    "\n",
    "steps:\n",
    "    1. Pre-processing\n",
    "    2. Group ICA\n",
    "    3. Dual regression\n",
    "    4. Component selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. pre-processing 100-HCP (unsmoothed cleaned resting state) participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "echo $workingDir\n",
    "\n",
    "module load fsl\n",
    "#----------------------------\n",
    "\n",
    "#  mkdir -p ${EPHEMERAL}/mica/${project}\n",
    "#  workingDir=${EPHEMERAL}/mica/${project}\n",
    "\n",
    "# Set empty command File \n",
    "echo -n \"\" > ${workingDir}/${project}_preproc_job.txt\n",
    "echo -n \"\" > ${workingDir}/HCP_rest_subj_path.txt\n",
    "\n",
    "# Get list of subjects\n",
    "for subj in `cat $subjects`; do  \n",
    "    ls ${hcpDir}/rest/${subj}/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR_hp2000_clean.nii.gz >> ${workingDir}/HCP_rest_subj_path.txt\n",
    "done\n",
    "   \n",
    "# Set job variables\n",
    "input=${workingDir}/HCP_rest_subj_path.txt\n",
    "mkdir -p ${workingDir}/rest\n",
    "outputDir=${workingDir}/rest\n",
    "#mask=${templates}/lesionMask2mm.nii.gz\n",
    "mask=${templates}/ACC_masks/${project}_MNI2mm.nii.gz\n",
    "template=/apps/fsl/5.0.10/fsl/data/standard/MNI152_T1_2mm_brain.nii.gz\n",
    "\n",
    "# -crop\n",
    "\n",
    "#~~~~~~~~~~~~~~~~~~~~~#\n",
    "# Run job\n",
    "#~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "# Set job in textfile for submission wrapper\n",
    "echo \"${fsl}; ${micaEx}; ${micaDir}/bin/mica_preproc $input $outputDir -smooth 3.0 -mask $mask -bgimage $template\" >> ${workingDir}/${project}_preproc_job.txt\n",
    "job=${workingDir}/${project}_preproc_job.txt\n",
    "\n",
    "    ## Run job\n",
    "    ${dep}/hpcSubmit ${job} 32:00:00 1 12Gb\n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"\n",
    "    cat ${job}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Group ICA\n",
    "\n",
    "The below cell generated the melodic commands using mica - this was serial so, I broke it up and paralleised it below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%script bash\n",
    "\n",
    "# #~~~~~~~~~~~~~~~~~~~~~#\n",
    "# # Set paths & tools\n",
    "# #~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "# project=`awk '{if(NR==1) print $0}' MICAsetup.txt`\n",
    "# dep=`awk '{if(NR==2) print $0}' MICAsetup.txt`\n",
    "# templates=`awk '{if(NR==3) print $0}' MICAsetup.txt`\n",
    "# workingDir=`awk '{if(NR==4) print $0}' MICAsetup.txt`\n",
    "\n",
    "# fsl=`awk '{if(NR==5) print $0}' MICAsetup.txt`\n",
    "# micaEx=`awk '{if(NR==6) print $0}' MICAsetup.txt`\n",
    "# micaDir=`awk '{if(NR==7) print $0}' MICAsetup.txt`\n",
    "\n",
    "# hcpDir=`awk '{if(NR==8) print $0}' MICAsetup.txt`\n",
    "# subjects=`awk '{if(NR==9) print $0}' MICAsetup.txt`\n",
    "\n",
    "# #~~~~~~~~~~~~~~~~~~~~~#\n",
    "# # Set variables\n",
    "# #~~~~~~~~~~~~~~~~~~~~~#\n",
    "\n",
    "# # Set empty command File \n",
    "# echo -n \"\" > ${workingDir}/${project}_ICA_job.txt\n",
    " \n",
    "# # Set command variables\n",
    "# input=${workingDir}/rest/input_preproc.txt # Should be created from previous step\n",
    "# mkdir -p ${workingDir}/ICA\n",
    "# outputDir=${workingDir}/ICA \n",
    "# mask=${workingDir}/rest/final_mask.nii.gz \n",
    "# template=${workingDir}/rest/bgimage.nii.gz\n",
    "\n",
    "# ## Set job\n",
    "\n",
    "# echo \"${fsl}; ${micaEx}; ${micaDir}/bin/mica $input $outputDir -dim 2-12 -mask $mask -merge-stats -parcel -extra --bgimage=$template --report --Ostats\" >> ${workingDir}/${project}_ICA_job.txt   \n",
    "# job=${workingDir}/${project}_ICA_job.txt\n",
    "# #\n",
    "\n",
    "#     # Run job\n",
    "#     ${dep}/hpcSubmit ${job} 62:00:00 1 12Gb\n",
    "#     echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"\n",
    "#     cat ${job}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reproducability analysis "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Starting Melodic ###\n",
    "\n",
    "No specified dimensions will take longer and has been failing..\n",
    "It took ~55hrs to run 100 subjects with a mask on the dim0 component (98 components came out)\n",
    "* Was run wiith unsmoothed data - likely to be quicker with 6mm smoothing. \n",
    "* dim 0 timed out with dual regression for 62hrs but with smoothing looks like will compleate. \n",
    "\n",
    "### Generate ICA-based Parcellation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "echo $workingDir\n",
    "\n",
    "module load fsl\n",
    "#----------------------------\n",
    "\n",
    "\n",
    "mkdir -p ${workingDir}/ICA\n",
    "outputDir=${workingDir}/ICA \n",
    "\n",
    "# Set empty command File \n",
    " echo -n \"\" > ${workingDir}/${project}_ICA_job.txt\n",
    "\n",
    "### Starting Melodic ###\n",
    "\n",
    "# dim0  \n",
    "#echo \"/apps/fsl/5.0.10/fsl/bin/melodic -i $workingDir/rest/input_preproc.txt -o ${outputDir}/dim0_run2 --mask=${workingDir}/rest/final_mask.nii.gz --bgimage=${workingDir}/rest/bgimage.nii.gz --report --Ostats\" >> ${workingDir}/${project}_ICA_job.txt     \n",
    "\n",
    "# dim 2-14\n",
    "for ii in {2..12};\n",
    "do\n",
    "   echo \"/apps/fsl/5.0.10/fsl/bin/melodic -i ${workingDir}/rest/input_preproc.txt -o ${outputDir}/dim${ii} --mask=${workingDir}/rest/final_mask.nii.gz --dim=${ii} --bgimage=${workingDir}/rest/bgimage.nii.gz --report --Ostats\" >> ${workingDir}/${project}_ICA_job.txt     \n",
    "done\n",
    "\n",
    "job=${workingDir}/${project}_ICA_job.txt\n",
    "#\n",
    "\n",
    "    # Run job\n",
    "    ${dep}/hpcSubmit ${job} 62:00:00 1 12Gb\n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"\n",
    "    cat ${job}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross correlation of components to check spatial overlap\n",
    "Go to stats dir generated with melodic above - Merge the thresholded Z maps into two 4D files and compare "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fslmerge -t all_threshZ_A `ls thresh*`\n",
    "fslmerge -t all_threshZ_B `ls thresh*`\n",
    "\n",
    "fslcc all_threshZ_A all_threshZ_B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatially smooth cleaned data for input into dual-regression\n",
    "* Don't need to rerun (unless altering smoothing kernal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "echo $workingDir\n",
    "\n",
    "module load fsl\n",
    "#----------------------------\n",
    "# Set empty command File \n",
    "echo -n \"\" > ${workingDir}/${project}_smooth_job.txt\n",
    "\n",
    "# Job\n",
    "ix=`cat $subjects`\n",
    "for subj in $ix; do\n",
    "    input=${hcpDir}/rest/${subj}/MNINonLinear/Results/rfMRI_REST1_LR/rfMRI_REST1_LR_hp2000_clean.nii.gz\n",
    "    output=${hcpDir}/rest/c3nl_processed/${subj}/rfMRI_REST1_LR_6mm_gauss\n",
    "    mkdir -p $output\n",
    "    echo \"${fsl}; fslmaths $input -kernel gauss 2.549987 -fmean $output/rfMRI_REST1_LR_hp2000_clean_6mm_gauss.nii.gz\" >> ${workingDir}/${project}_smooth_job.txt\n",
    "done\n",
    "\n",
    "job=${workingDir}/${project}_smooth_job.txt\n",
    "\n",
    "    # Run job\n",
    "    ${dep}/hpcSubmit ${job} 02:00:00 1 12Gb\n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Head submitted commands:\"\n",
    "    head ${job}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dual-regression (inc. grey matter mask)\n",
    "\n",
    "Take melodic ICA output of the earlier step for each component, and use this to drive dual regression which back projects onto individual data (This should be done on smoothed input [6mm]). This is done in three steps:  \n",
    "\n",
    "\n",
    "**Timecourses at subject level**\n",
    "> For each subject, apply the spatial (sub)component masks and thus derive (regress) average time series.\n",
    "\n",
    "**Spatial maps at subject level**\n",
    "> For each timeseries derived above, identify (regress) whole brain spatial map of areas of co-activation.\n",
    "\n",
    "**Permutation testing**\n",
    "> \n",
    "--  \n",
    "\n",
    "May also run faster after smoothing.. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "echo $workingDir\n",
    "\n",
    "module load fsl\n",
    "#----------------------------\n",
    "\n",
    "\n",
    "# Set empty command File \n",
    "echo -n \"\" > ${workingDir}/${project}_dual_job.txt\n",
    "\n",
    "echo -n \"\" > ${workingDir}/6mm_subj.txt\n",
    "for ii in `cat $subjects`; do\n",
    "   ls ${hcpDir}/rest/c3nl_processed/${ii}/rfMRI_REST1_LR_6mm_gauss/* >> ${workingDir}/6mm_subj.txt\n",
    "done\n",
    "\n",
    "# Command input variables\n",
    "subjects=${workingDir}/6mm_subj.txt\n",
    "ROI_mask=${templates}/ACC_masks/${project}_MNI2mm_mask.nii.gz #ROI_mask=${templates}/lesionMask2mm.nii.gz #\n",
    "brain_mask=${templates}/MNI152_T1_2mm_brain_pve_1_mask.nii.gz # GM masking\n",
    "ICAdir=${workingDir}/ICA\n",
    "\n",
    "# Settings: \n",
    "des_norm=1; # whether to variance normalise the time courses used in the stage 2 regression\n",
    "designmat=-1; # specify we are doing a one sample t test model **CHECK \n",
    "designcon=-1;\n",
    "designfts=0;\n",
    "designgrp=0;\n",
    "n_perm=5000 #1; # specify number of permutations for randomise\n",
    "\n",
    "\n",
    "# Command\n",
    "for directory in `ls -d $ICAdir/*/` ;\n",
    "do\n",
    "    dim=`basename $directory`;\n",
    "    groupICA=${ICAdir}/${dim}/melodic_IC.nii.gz\n",
    "    output=$workingDir/${projectLabel}/DR6mm/pve1Masked_${dim}_dual_regression\n",
    "    # ${designcon} # removed as $designmat is set to -1\n",
    "    echo \"${fsl}; ${micaEx}; ${micaDir}/bin/dual_regression_roi ${groupICA} ${des_norm} ${ROI_mask} ${brain_mask} ${designmat} ${designfts} ${designgrp} ${n_perm} ${output} -in-step1 \\`cat $subjects\\` -in-step2 \\`cat $subjects\\`\" >> ${workingDir}/${project}_dual_job.txt;      \n",
    "\n",
    "done\n",
    "\n",
    "job=${workingDir}/${project}_dual_job.txt\n",
    "\n",
    "    # Run job\n",
    "    ${dep}/hpcSubmit ${job} 68:00:00 1 12Gb\n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"\n",
    "    head ${job}\n",
    "    \n",
    "# Usage: dual_regression <group_IC_maps> <des_norm> <step1_mask> <step2_mask> <design.mat> <design.con> <design.fts> <design.grp> <n_perm> <output_directory> -in-step1 <input1> <input2> ... -in-step2 <input1> <input2> ...\n",
    "# e.g.   dual_regression groupICA.gica/groupmelodic.ica/melodic_IC 1 design.mat design.con 500 grot \\`cat groupICA.gica/.filelist\\`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Component Selection:  \n",
    "Have a reasonable amount of components you want to use, based on previous literature, after removing noise. Or quantitative analysis from generate multiple components.   \n",
    "\n",
    "Worth looking at how components vary and what regions share common variance \n",
    "\n",
    "    fslmaths\n",
    "    -Tmean\n",
    "    -inverse warp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducibility Analysis\n",
    "(notes from Richard)\n",
    "\n",
    "The approach detailed in mICA produces an estimate for ideal dimensionality for decomposition. This is necessary because: the underlying dimensionality is not known in fMRI data, different instantiations (realisations) of ICA for the same dimensionality produce different components, and the stability of components will differ across dimensionalities. The approach is as below:\n",
    "\n",
    "The following discussion was helpful to developing these cells: https://www.nitrc.org/forum/message.php?msg_id=24083\n",
    "\n",
    "Permutation of group membership\n",
    "> The group is split in 2 in different ways, for N permutations. Each permutation is then subjected to group mICA.\n",
    "\n",
    "Exploration of dimensionalities\n",
    "> The above process is done across a range of dimensionalities.\n",
    "\n",
    "Minimising temporal cross-correlation\n",
    "> iccorr.py uses fslcc to produce 'spatial' cross-correlations between group 1 and group 2. Within each dimensionality, across permutations, cross-correlations are calculated. Negative cross-correlations are removed, then the result is subtracted from 1 to give a 'cost'. 'Cost' is high where components are highly independent, and low when they are highly related. This cost matrix is then sorted, such that components are aligned - so the diagnoal of the matrix represents the cost for two equivalent components; again if they are more similar, the cost is low (high reproducibility). The mean of this diagonal is then taken as a measure of the cost or this dimension and permutation. \n",
    "\n",
    "> Mean 'cost' is thus the mean for a dimension across permutations, and a lower value corresponds to greater reproducibility.\n",
    "\n",
    "Practically, this process is computationally intensive. Given the strengths of the HPC (array computing), and that the number of permutations will likely exceed the dimensionality count, the goal is to run D dimensionality jobs each with N permutations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the split group reproducability analysis\n",
    "### STEP 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "echo $workingDir\n",
    "\n",
    "module load fsl\n",
    "ICAAROMA=~/c3nl_tools/ICA-AROMA-master/ICA_AROMA.py\n",
    "aroma=\"source activate aroma\"\n",
    "#----------------------------\n",
    "\n",
    "\n",
    "# Set empty command File \n",
    "echo -n \"\" > ${workingDir}/${project}_reproducability_job.txt\n",
    "\n",
    "# run splithalf\n",
    "reproducibility_permutations=50\n",
    "reproducibility_dimensions=\"2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50\";\n",
    "mkdir -p $workingDir/reproducibility_dir\n",
    "reproducibility_dir=$workingDir/reproducibility_dir\n",
    "\n",
    "echo \"${aroma}; ${micaEx}; python ${micaDir}/py/splithalf.py $workingDir/rest/input_preproc.txt ${reproducibility_permutations} ${reproducibility_dir}\" >> ${workingDir}/${project}_reproducability_job.txt\n",
    "\n",
    "job=${workingDir}/${project}_reproducability_job.txt\n",
    "\n",
    "    # Run job\n",
    "    ${dep}/hpcSubmit ${job} 71:00:00 1 12Gb\n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"\n",
    "    cat ${job}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2.\n",
    "\n",
    "Loop over the 50 samples in each of the split groups 1 & 2 -> Run x dim for each. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "echo $workingDir\n",
    "\n",
    "module load fsl\n",
    "ICAAROMA=~/c3nl_tools/ICA-AROMA-master/ICA_AROMA.py\n",
    "aroma=\"source activate aroma\"\n",
    "#----------------------------\n",
    "\n",
    "# Set empty command File \n",
    "echo -n \"\" > ${workingDir}/${project}_bigICA_job.txt\n",
    "\n",
    "mkdir -p ${workingDir}/ICA\n",
    "outputDir=${workingDir}/ICA \n",
    "\n",
    "\n",
    "### Starting Melodic ###\n",
    "for group in {1..2};\n",
    "    do\n",
    "    for sample in `ls $workingDir/reproducibility_dir`;\n",
    "        do\n",
    "        for dim in {2..50};\n",
    "            do\n",
    "            echo \"${fsl}; /apps/fsl/5.0.10/fsl/bin/melodic -i $workingDir/reproducibility_dir/${sample}/group${group}_input.txt -o $workingDir/reproducibility_dir/${sample}/group${group}/dim${dim} --mask=$workingDir/rest/final_mask.nii.gz --dim=${dim} --bgimage=$workingDir/rest/bgimage.nii.gz --report --Ostats\" >> ${workingDir}/${project}_bigICA_job.txt    \n",
    "        done\n",
    "    done\n",
    "done\n",
    "\n",
    "job=${workingDir}/${project}_bigICA_job.txt\n",
    "\n",
    "    # Run job\n",
    "    ${dep}/hpcSubmit ${job} 24:00:00 1 12Gb\n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"\n",
    "    head ${job}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3 - running the reproducibility analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "echo $workingDir\n",
    "\n",
    "module load fsl\n",
    "ICAAROMA=~/c3nl_tools/ICA-AROMA-master/ICA_AROMA.py\n",
    "\n",
    "# aroma=\"source activate aroma\" # missing munkes package, could just install\n",
    "aroma=\"source activate py27\"\n",
    "#----------------------------\n",
    "\n",
    "# /share/apps/fsl/bin/fsl_sub -N mICASplitHalf_step3 -T 30 -l /group/HCP/analysis/SaraStriatum/test_reprodcommand/tmp_log python /share/apps/mICA/mICA_Toolbox/py/ic_corr.py /group/HCP/analysis/SaraStriatum/test_reprodcommand 50 2-20\n",
    "\n",
    "mkdir -p ${workingDir}/reproducibility_dir\n",
    "reproducibility_permutations=50\n",
    "reproducibility_dimensions=\"2-50\";\n",
    "\n",
    "echo \"${aroma}; ${micaEx}; python ${micaDir}/py/ic_corr.py ${workingDir}/reproducibility_dir ${reproducibility_permutations} ${reproducibility_dimensions} 1\" > ${workingDir}/${project}_step3_RA_job.txt\n",
    "\n",
    "    job=${workingDir}/${project}_step3_RA_job.txt\n",
    "    # Run job\n",
    "    ${dep}/hpcSubmit ${job} 42:00:00 1 12Gb\n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"\n",
    "    head ${job}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validate ICA result at chosen dimensionality - Spatial and Temporal Correlation, and Spatial Similarity\n",
    "As per De Simoni et al. 2018, if ICA has been effective, then:\n",
    "1. Spatial correlation will be low between components within ROI mask.\n",
    "2. Also Spatial similarity (Dice) should be low.\n",
    "2. Finally temporal correlation will also be low.\n",
    "\n",
    "Practically, for now, I opt to look at spatial similarity (Dice co-efficient), and temporal cross-correlation using ```fslcc``."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spatial Correlation of Components\n",
    "Pearson's Spatial Correlation defined as in https://www.jiscmail.ac.uk/cgi-bin/webadmin?A2=fsl;1057accd.1202\n",
    "The result will be a matrix (csv) of maps vs. maps, with inter-component spatial similarity as the value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "\n",
    "dims_stats=20\n",
    "\n",
    "for dim in ${dims_stats};\n",
    "do\n",
    "\n",
    "    echo \"Preparing environment variables and folders for dimension $dim\";\n",
    "    \n",
    "    $(: Subfolder to save results in)\n",
    "    export run=maskthresh_${mask_thresh}_ROP2_GM${gmseg_thresh_pct}_dim_${dim}_drGMmask;\n",
    "    echo mICA will be save to subfolder \\$run;\n",
    "    \n",
    "    $(: mICA results folders)\n",
    "    export mica_group_ica=${ANALYSISDIR}/mica_group_ica_\\${run};\n",
    "    export mica_dual_regression=${ANALYSISDIR}/mica_dual_regression_\\${run};\n",
    "    check_exists \\${mica_group_ica} \\\"mICA group ica folder set\\\";\n",
    "    check_exists \\${mica_dual_regression} \\\"mICA dual regression folder set\\\";   \n",
    "    results_folder=\\${mica_dual_regression};\n",
    "\n",
    "    $(: where results are saved)\n",
    "    csv=$ANALYSISDIR/component_spatial_correlation_\\${run}.csv;\n",
    "    \n",
    "    \n",
    "    echo \"One minus p setting is $oneminusp\" > $ANALYSISDIR/component_spatial_correlation_settings_\\${run}.txt;\n",
    "    echo \"Results will be saved to \\$csv\";\n",
    "   \n",
    "    $(:  where intermediate files go)\n",
    "    components_folder=${inputs_folder}/component_spatial_correlation_\\${run};\n",
    "    \n",
    "    $(: where is the melodic file)\n",
    "    melodic_file=\\${mica_group_ica}/dim${dim}/melodic_IC.nii.gz;\n",
    "\n",
    "\n",
    "    check_exists \\${components_folder} \\\"Created dice folder\\\";\n",
    "    rm \\${components_folder}/components*;\n",
    "    \n",
    "    $(: Extract components to components folder)\n",
    "    \n",
    "    fslsplit \\${melodic_file} \\${components_folder}/components;\n",
    "    \n",
    "    echo Producing a list of components in \\${components_folder};\n",
    "    cd \\${components_folder};\n",
    "    \n",
    "    components=\\$(ls);\n",
    "    components_array=(\\$components);\n",
    "    num_components=\\$(echo \\$components | wc -w);\n",
    "    echo \\${num_components} components found;\n",
    "    names=\\\"\\\";\n",
    "    names_header=\\\"\\\";\n",
    "    \n",
    "    $(: extract names)\n",
    "    echo Getting component names;\n",
    "    for i in \\$(seq 1 \\${num_components});\n",
    "    do\n",
    "        iminus1=\\$((\\$i - 1 ));\n",
    "        tempname=\\`echo \\${components_array[\\$iminus1]} | grep -o -P '(?<=components).*(?=.nii.gz)'\\`;\n",
    "        names=\\\"\\${names} \\${tempname}\\\";\n",
    "        names_header=\\\"\\${names_header},\\${tempname}\\\";\n",
    "    done;\n",
    "    names_array=(\\$names);\n",
    "    \n",
    "\n",
    "    $(: write csv header)\n",
    "    echo \\${names_header}>\\${csv};\n",
    "\n",
    "    cd \\${components_folder};\n",
    "    $(: for each component, for each other component, calculate spatial similarity between i and j)\n",
    "    $(: Let a is component file for i, and b be component file for j, A is volume of a, B is volume of b, AnB is the intersection of A and B)\n",
    "    $(:  So dice D is 2xAnB div A + B)\n",
    "    \n",
    "    \n",
    "    echo Working through each component row;\n",
    "    for i in \\$(seq 0 \\$((\\${num_components} - 1)));\n",
    "    do\n",
    "        $(: row header)\n",
    "        row=\\\"\\\";\n",
    "        row_header=\\${names_array[\\${i}]};\n",
    "        row=\\${row_header};\n",
    "        a=\\${components_folder}/\\${components_array[\\$i]};\n",
    "        $(: mask )\n",
    "        MA=$(fslstats \\$a -k $mask -m);\n",
    "        $(: demeaned and sqr root demeaned)\n",
    "        demeaned_a=${inputs_folder}/a_\\${names_array[\\$i]}_demeaned.nii.gz;\n",
    "        fslmaths \\${a} -sub \\$MA -mas $mask \\${demeaned_a};\n",
    "        demeaned_sqr_a=${inputs_folder}/a_\\${names_array[\\$i]}_demeaned_sqr.nii.gz;\n",
    "        fslmaths \\${demeaned_a} -sqr \\${demeaned_sqr_a};\n",
    "        den_a=\\$(fslstats \\${demeaned_sqr_a} -k $mask -m);\n",
    "\n",
    "\n",
    "        echo Component \\${names_array[\\$i]} has volume \\$A;\n",
    "        for j in \\$(seq 0 \\$((\\${num_components} - 1)));\n",
    "        do\n",
    "\n",
    "            b=\\${components_folder}/\\${components_array[\\$j]};\n",
    "            $(: mask )\n",
    "            MB=$(fslstats \\$b -k $mask -m);\n",
    "            $(: demeaned and sqr root demeaned)\n",
    "            demeaned_b=${inputs_folder}/b_\\${names_array[\\$j]}_demeaned.nii.gz;\n",
    "            fslmaths \\${b} -sub \\$MB -mas $mask \\${demeaned_b};\n",
    "            demeaned_sqr_b=${inputs_folder}/b_\\${names_array[\\$j]}_demeaned_sqr.nii.gz;\n",
    "            fslmaths \\${demeaned_b} -sqr \\${demeaned_sqr_b};\n",
    "            den_b=\\$(fslstats \\${demeaned_sqr_b} -k $mask -m);\n",
    "\n",
    "           $(: more work)\n",
    "\n",
    "            demeaned_prod=${inputs_folder}/prod_\\${names_array[\\$i]}_\\${names_array[\\$j]}_demeaned.nii.gz;\n",
    "            fslmaths \\${demeaned_a} -mul \\${demeaned_b} \\${demeaned_prod};\n",
    "            num=\\$(fslstats \\${demeaned_prod} -k $mask -m);\n",
    "            denprod=\\$(echo \\\"scale=${bc_scale}; sqrt(\\${den_a}*\\${den_b})\\\" | bc -l);\n",
    "            true_r=\\$(echo \\\"scale=${bc_scale}; \\${num}/\\${denprod}\\\" | bc -l);\n",
    "            \n",
    "             $(: Pearson)\n",
    "           \n",
    "            $(: update row)\n",
    "            row=\\\"\\${row},\\${true_r}\\\";\n",
    "                   \n",
    "            \n",
    "        done;\n",
    "        $(: add row to csv)\n",
    "        echo \\${row} >> \\$csv;\n",
    "    done\";\n",
    "                    \n",
    "    echo ${inputcommands//$'\\n'/ }>>$notebookpath/hcpvestibular_component_spatial_correlation${randref}.txt;\n",
    "\n",
    "echo Finished for dimension $dim with results in $csv;\n",
    "done;\n",
    "                      \n",
    "                      \n",
    "cd $notebookpath/logs;\n",
    "$notebookpath/dependencies/phd_hpc_submit.sh \"$notebookpath/hcpvestibular_component_spatial_correlation${randref}.txt\" 0:30:00 1 2Gb $notebookpath/hcpvestibular_fourth${randref}_${dim}.txt\n",
    "\n",
    "\n",
    "echo All done with spatial similarity for all dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing dataset:\n",
    "\n",
    "## Pre-processing resting state data run with rest_preproc.ipynb notebook\n",
    "\n",
    "This involves:\n",
    "1. Setup dependencies & project directories\n",
    "2. Skull stripping using BET in FSL\n",
    "3. Lower level FEAT (without high-pass filtering because of ICA AROMA) - the preprocessing tabs\n",
    "        - motion correction\n",
    "        - slice timing correction\n",
    "        - spatial smoothing\n",
    "        - registration\n",
    "4. Create functional masks\n",
    "5. Run matlab script to calculate 24 motion parameters = .txt file to include in stage 8 (ORDER OF THIS??)\n",
    "6. Identifying motion, artifacts, noise components \n",
    "        5a. ICA AROMA\n",
    "        5b. Motion outliers   \n",
    "7. Denoising using components\n",
    "8. Regress out white matter, CSF and motion paramters (6 that came from MCFLIRT +18)\n",
    "9. Lower level FEAT of cleaned data (with high-pass filtering) - the preprocessing tabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of filtered func clean data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binerising networks from HCP data for use as masks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rds/general/user/nbourke/ephemeral/mica/lesion\n",
      "00\n",
      "01\n",
      "02\n",
      "03\n",
      "04\n",
      "05\n",
      "06\n",
      "07\n",
      "08\n",
      "09\n",
      "10\n",
      "11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: $PATH does not agree with $PATH_modshare counter. The following directories' usage counters were adjusted to match. Note that this may mean that module unloading may not work correctly.\n",
      " /home/nbourke/anaconda3/envs/py27/bin /apps/gcc/6.2.0/ /opt/ibutils/bin /rds/general/user/nbourke/home/anaconda3/bin /apps/mrtrix/3.0/bin /apps/ants/2015-02-23/bin/bin /apps/gcc/6.2.0/bin /usr/local/sbin /opt/pbs/bin /usr/lib64/qt-3.3/bin /apps/ants/2015-02-23/bin/ /rds/general/user/nbourke/home/perl5/bin /apps/anaconda3/4.5.12/install\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "echo $workingDir\n",
    "\n",
    "module load fsl\n",
    "#----------------------------\n",
    "#workingDir=/rds/general/user/nbourke/home/projects/micaOutput/rostalACC\n",
    "\n",
    "drDir=${workingDir}/DR6mm/pve1Masked_dim12_dual_regression # $workingDir/DR6mm/pve1Masked_dim12_dual_regression # \n",
    "groupICA=${ICAdir}/dim12/melodic_IC.nii.gz # $workingDir/ICA/dim12/melodic_IC.nii.gz   #\n",
    "\n",
    "\n",
    "for dim in $(seq -f \"%02g\" 0 11)\n",
    "do\n",
    "\n",
    "    #options\n",
    "    network=${drDir}/dr_stage3_ic00${dim}_tfce_corrp_tstat1.nii.gz\n",
    "    threshold=0.95\n",
    "    maskOut=$workingDir/networkMasks\n",
    "    mkdir -p $maskOut\n",
    "    \n",
    "    #Command\n",
    "    fslmaths $network -thr $threshold -bin ${maskOut}/IC_${dim}_mask\n",
    "\n",
    "done\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dual-regression (back projection) of HCP defined components to a test data set\n",
    "##### (could include neuropsych in design matrix)\n",
    "\n",
    "1. Select dimension from HCP data to run\n",
    "2. Choose components to run from this.\n",
    "3. For each component from the HCP apply spatial & temporal back projection (melodic_IC) to new test dataset using a HCP mask for that network\n",
    "\n",
    "\n",
    "##### Caudal ACC\n",
    "0 - keep  \n",
    "1 - ?  \n",
    "2 - keep  \n",
    "3 - ?  \n",
    "4 - keep (nosiy DMN)  \n",
    "5 - x  \n",
    "6 - keep  \n",
    "7 - keep (cleaner DMN)  \n",
    "8 - ACC  \n",
    "9 - keep subcortical  \n",
    "10 - x  \n",
    "11 - x  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processed test set\n",
    "* Collate tesing data subjects for the following steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "echo $workingDir\n",
    "\n",
    "echo \"\" > ~/projects/squeezy/derivatives/con_ffdc.txt\n",
    "\n",
    "for ii in `ls -d ~/projects/squeezy/derivatives/controlTestSet/*/`;\n",
    "do\n",
    "    subj=`basename $ii`\n",
    "    fullpath=${ii}/func/rest/postICA.feat/filtered_func_data_clean_standard.nii.gz \n",
    "    echo $fullpath >> ~/projects/squeezy/derivatives/con_ffdc.txt\n",
    "done\n",
    "\n",
    "#ls ~/eph/DREAM_REST_clean/* >> ~/projects/squeezy/derivatives/dream_ffdc.txt\n",
    "# At some point I manually selected the patients of interest from this list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing group dual regression with derived network masks\n",
    "* Why is there no output for this - did it fail?  \n",
    "* Paths to data have now changed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/rds/general/user/nbourke/ephemeral/mica/caudalACC\n",
      "input is = /rds/general/user/nbourke/ephemeral/mica/caudalACC/caudalACC_testSet_analysis_job.txt\n",
      "Walltime = 36:00:00\n",
      "Number of CPUs = 1\n",
      "Memory = 12Gb\n",
      "Array jobs submitted: 13\n",
      "Job submitted: Mon 20 Jan 17:56:24 GMT 2020\n",
      "979305[].pbs\n",
      "\n",
      "***\n",
      "\n",
      "Submitted commands:\n",
      "\n",
      "module load fsl; export MICADIR=/rds/general/project/c3nl_shared/live/dependencies/mICA_Toolbox; /rds/general/project/c3nl_shared/live/dependencies/mICA_Toolbox/bin/dual_regression_roi /rds/general/user/nbourke/ephemeral/mica/caudalACC/test/melodic_IC.nii.gz 1 /rds/general/user/nbourke/ephemeral/mica/caudalACC/networkMasks/IC_00_mask.nii.gz /rds/general/user/nbourke/home/templates/MNI152_T1_2mm_brain_pve_1_mask.nii.gz /rds/general/user/nbourke/home/projects/squeezy/scripts/design/basic.mat /rds/general/user/nbourke/home/projects/squeezy/scripts/design/contrast.con 0 0 5000 /rds/general/user/nbourke/ephemeral/mica/caudalACC/test/randomise_output/dim00 -in-step1 ` cat /rds/general/user/nbourke/home/projects/squeezy/scripts/subPaths.txt` -in-step2 ` cat /rds/general/user/nbourke/home/projects/squeezy/scripts/subPaths.txt`\n",
      "module load fsl; export MICADIR=/rds/general/project/c3nl_shared/live/dependencies/mICA_Toolbox; /rds/general/project/c3nl_shared/live/dependencies/mICA_Toolbox/bin/dual_regression_roi /rds/general/user/nbourke/ephemeral/mica/caudalACC/test/melodic_IC.nii.gz 1 /rds/general/user/nbourke/ephemeral/mica/caudalACC/networkMasks/IC_01_mask.nii.gz /rds/general/user/nbourke/home/templates/MNI152_T1_2mm_brain_pve_1_mask.nii.gz /rds/general/user/nbourke/home/projects/squeezy/scripts/design/basic.mat /rds/general/user/nbourke/home/projects/squeezy/scripts/design/contrast.con 0 0 5000 /rds/general/user/nbourke/ephemeral/mica/caudalACC/test/randomise_output/dim01 -in-step1 ` cat /rds/general/user/nbourke/home/projects/squeezy/scripts/subPaths.txt` -in-step2 ` cat /rds/general/user/nbourke/home/projects/squeezy/scripts/subPaths.txt`\n",
      "module load fsl; export MICADIR=/rds/general/project/c3nl_shared/live/dependencies/mICA_Toolbox; /rds/general/project/c3nl_shared/live/dependencies/mICA_Toolbox/bin/dual_regression_roi /rds/general/user/nbourke/ephemeral/mica/caudalACC/test/melodic_IC.nii.gz 1 /rds/general/user/nbourke/ephemeral/mica/caudalACC/networkMasks/IC_02_mask.nii.gz /rds/general/user/nbourke/home/templates/MNI152_T1_2mm_brain_pve_1_mask.nii.gz /rds/general/user/nbourke/home/projects/squeezy/scripts/design/basic.mat /rds/general/user/nbourke/home/projects/squeezy/scripts/design/contrast.con 0 0 5000 /rds/general/user/nbourke/ephemeral/mica/caudalACC/test/randomise_output/dim02 -in-step1 ` cat /rds/general/user/nbourke/home/projects/squeezy/scripts/subPaths.txt` -in-step2 ` cat /rds/general/user/nbourke/home/projects/squeezy/scripts/subPaths.txt`\n",
      "module load fsl; export MICADIR=/rds/general/project/c3nl_shared/live/dependencies/mICA_Toolbox; /rds/general/project/c3nl_shared/live/dependencies/mICA_Toolbox/bin/dual_regression_roi /rds/general/user/nbourke/ephemeral/mica/caudalACC/test/melodic_IC.nii.gz 1 /rds/general/user/nbourke/ephemeral/mica/caudalACC/networkMasks/IC_03_mask.nii.gz /rds/general/user/nbourke/home/templates/MNI152_T1_2mm_brain_pve_1_mask.nii.gz /rds/general/user/nbourke/home/projects/squeezy/scripts/design/basic.mat /rds/general/user/nbourke/home/projects/squeezy/scripts/design/contrast.con 0 0 5000 /rds/general/user/nbourke/ephemeral/mica/caudalACC/test/randomise_output/dim03 -in-step1 ` cat /rds/general/user/nbourke/home/projects/squeezy/scripts/subPaths.txt` -in-step2 ` cat /rds/general/user/nbourke/home/projects/squeezy/scripts/subPaths.txt`\n",
      "module load fsl; export MICADIR=/rds/general/project/c3nl_shared/live/dependencies/mICA_Toolbox; /rds/general/project/c3nl_shared/live/dependencies/mICA_Toolbox/bin/dual_regression_roi /rds/general/user/nbourke/ephemeral/mica/caudalACC/test/melodic_IC.nii.gz 1 /rds/general/user/nbourke/ephemeral/mica/caudalACC/networkMasks/IC_04_mask.nii.gz /rds/general/user/nbourke/home/templates/MNI152_T1_2mm_brain_pve_1_mask.nii.gz /rds/general/user/nbourke/home/projects/squeezy/scripts/design/basic.mat /rds/general/user/nbourke/home/projects/squeezy/scripts/design/contrast.con 0 0 5000 /rds/general/user/nbourke/ephemeral/mica/caudalACC/test/randomise_output/dim04 -in-step1 ` cat /rds/general/user/nbourke/home/projects/squeezy/scripts/subPaths.txt` -in-step2 ` cat /rds/general/user/nbourke/home/projects/squeezy/scripts/subPaths.txt`\n",
      "module load fsl; export MICADIR=/rds/general/project/c3nl_shared/live/dependencies/mICA_Toolbox; /rds/general/project/c3nl_shared/live/dependencies/mICA_Toolbox/bin/dual_regression_roi /rds/general/user/nbourke/ephemeral/mica/caudalACC/test/melodic_IC.nii.gz 1 /rds/general/user/nbourke/ephemeral/mica/caudalACC/networkMasks/IC_05_mask.nii.gz /rds/general/user/nbourke/home/templates/MNI152_T1_2mm_brain_pve_1_mask.nii.gz /rds/general/user/nbourke/home/projects/squeezy/scripts/design/basic.mat /rds/general/user/nbourke/home/projects/squeezy/scripts/design/contrast.con 0 0 5000 /rds/general/user/nbourke/ephemeral/mica/caudalACC/test/randomise_output/dim05 -in-step1 ` cat /rds/general/user/nbourke/home/projects/squeezy/scripts/subPaths.txt` -in-step2 ` cat /rds/general/user/nbourke/home/projects/squeezy/scripts/subPaths.txt`\n",
      "module load fsl; export MICADIR=/rds/general/project/c3nl_shared/live/dependencies/mICA_Toolbox; /rds/general/project/c3nl_shared/live/dependencies/mICA_Toolbox/bin/dual_regression_roi /rds/general/user/nbourke/ephemeral/mica/caudalACC/test/melodic_IC.nii.gz 1 /rds/general/user/nbourke/ephemeral/mica/caudalACC/networkMasks/IC_06_mask.nii.gz /rds/general/user/nbourke/home/templates/MNI152_T1_2mm_brain_pve_1_mask.nii.gz /rds/general/user/nbourke/home/projects/squeezy/scripts/design/basic.mat /rds/general/user/nbourke/home/projects/squeezy/scripts/design/contrast.con 0 0 5000 /rds/general/user/nbourke/ephemeral/mica/caudalACC/test/randomise_output/dim06 -in-step1 ` cat /rds/general/user/nbourke/home/projects/squeezy/scripts/subPaths.txt` -in-step2 ` cat /rds/general/user/nbourke/home/projects/squeezy/scripts/subPaths.txt`\n",
      "module load fsl; export MICADIR=/rds/general/project/c3nl_shared/live/dependencies/mICA_Toolbox; /rds/general/project/c3nl_shared/live/dependencies/mICA_Toolbox/bin/dual_regression_roi /rds/general/user/nbourke/ephemeral/mica/caudalACC/test/melodic_IC.nii.gz 1 /rds/general/user/nbourke/ephemeral/mica/caudalACC/networkMasks/IC_07_mask.nii.gz /rds/general/user/nbourke/home/templates/MNI152_T1_2mm_brain_pve_1_mask.nii.gz /rds/general/user/nbourke/home/projects/squeezy/scripts/design/basic.mat /rds/general/user/nbourke/home/projects/squeezy/scripts/design/contrast.con 0 0 5000 /rds/general/user/nbourke/ephemeral/mica/caudalACC/test/randomise_output/dim07 -in-step1 ` cat /rds/general/user/nbourke/home/projects/squeezy/scripts/subPaths.txt` -in-step2 ` cat /rds/general/user/nbourke/home/projects/squeezy/scripts/subPaths.txt`\n",
      "module load fsl; export MICADIR=/rds/general/project/c3nl_shared/live/dependencies/mICA_Toolbox; /rds/general/project/c3nl_shared/live/dependencies/mICA_Toolbox/bin/dual_regression_roi /rds/general/user/nbourke/ephemeral/mica/caudalACC/test/melodic_IC.nii.gz 1 /rds/general/user/nbourke/ephemeral/mica/caudalACC/networkMasks/IC_08_mask.nii.gz /rds/general/user/nbourke/home/templates/MNI152_T1_2mm_brain_pve_1_mask.nii.gz /rds/general/user/nbourke/home/projects/squeezy/scripts/design/basic.mat /rds/general/user/nbourke/home/projects/squeezy/scripts/design/contrast.con 0 0 5000 /rds/general/user/nbourke/ephemeral/mica/caudalACC/test/randomise_output/dim08 -in-step1 ` cat /rds/general/user/nbourke/home/projects/squeezy/scripts/subPaths.txt` -in-step2 ` cat /rds/general/user/nbourke/home/projects/squeezy/scripts/subPaths.txt`\n"
     ]
    }
   ],
   "source": [
    "%%bash -s \"$setup\"\n",
    "export setup=$1;\n",
    "source $setup\n",
    "echo $workingDir\n",
    "\n",
    "#jobfile\n",
    "echo \"\" > ${workingDir}/${project}_testSet_analysis_job.txt;  \n",
    "job=${workingDir}/${project}_testSet_analysis_job.txt;  \n",
    "\n",
    "# -- Specify Input --#\n",
    "\n",
    "testDir=$workingDir/test\n",
    "mkdir -p ${testDir}\n",
    "cp $workingDir/ICA/dim12/melodic_IC.nii.gz ${testDir}\n",
    "\n",
    "# Options\n",
    "IC_map=${testDir}/melodic_IC.nii.gz # This is the HCP melodic (components defined with this)\n",
    "input=~/projects/squeezy/scripts/subPaths.txt\n",
    "brain_mask=${templates}/MNI152_T1_2mm_brain_pve_1_mask.nii.gz # GM masking\n",
    "des_norm=1; # whether to variance normalise the time courses used in the stage 2 regression\n",
    "design_mat=~/projects/squeezy/scripts/design/basic.mat #change path\n",
    "design_con=~/projects/squeezy/scripts/design/contrast.con # change path\n",
    "designfts=0;\n",
    "designgrp=0;\n",
    "n_perm=5000\n",
    "\n",
    "\n",
    "# Loop over networks to back project with\n",
    "for dim in $(seq -f \"%02g\" 0 11);\n",
    "    do\n",
    "    HCP_mask=$workingDir/networkMasks/IC_${dim}_mask.nii.gz\n",
    "    output=${testDir}/randomise_output/dim${dim}\n",
    "    mkdir -p $output\n",
    "    \n",
    "    # dual regression\n",
    "    echo \"${fsl}; ${micaEx}; ${micaDir}/bin/dual_regression_roi ${IC_map} ${des_norm} ${HCP_mask} ${brain_mask} ${design_mat} ${design_con} ${designfts} ${designgrp} ${n_perm} ${output} -in-step1 \\` cat $input\\` -in-step2 \\` cat $input\\`\" >> ${job} ;      \n",
    "    done\n",
    "    \n",
    "    # Run job\n",
    "    ${dep}/hpcSubmit ${job} 36:00:00 1 12Gb\n",
    "    echo \"\"; echo \"***\"; echo \"\"; echo \"Submitted commands:\"\n",
    "    head ${job}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting mean timeseries for each network component "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to save files with id to run meants "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash -s \"$setup\"\n",
    "# export setup=$1;\n",
    "# source $setup\n",
    "# #echo $workingDir\n",
    "# workingDir=/rds/general/user/nbourke/home/projects\n",
    "# #------------------\n",
    "\n",
    "# mkdir ${workingDir}/squeezy/derivatives/socRest\n",
    "# data=${workingDir}/squeezy/derivatives/controlTestSet/\n",
    "# for subj in `ls $data`; \n",
    "# do\n",
    "#    cp ${data}/${subj}/func/rest/postICA.feat/filtered_func_data_clean_standard.nii.gz ${workingDir}/squeezy/derivatives/socRest/${subj}_ffdcs.nii.gz\n",
    "# done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%bash -s \"$setup\"\n",
    "# export setup=$1;\n",
    "# source $setup\n",
    "# #echo $workingDir\n",
    "# workingDir=/rds/general/user/nbourke/home/projects\n",
    "\n",
    "# module load fsl\n",
    "# # -- Specify Input --#\n",
    "\n",
    "# # Options\n",
    "# input=${workingDir}/squeezy/scripts/socSubj.txt\n",
    "# brain_mask=${templates}/MNI152_T1_2mm_brain_pve_1_mask.nii.gz # GM masking\n",
    "\n",
    "# # Mean time series extraction for network masks\n",
    "# for subj in `cat $input`;\n",
    "# do\n",
    "#     sub=`basename ${subj}`\n",
    "# #     NAME=${sub%/*/*/*/*}\n",
    "# #     id=${NAME##*/}\n",
    "\n",
    "#     for dim in 0 2 4 6 7 8 9;\n",
    "#     do\n",
    "#         HCP_mask=$workingDir/micaOutput/caudalACC/networkMasks/IC_0${dim}_maks.nii.gz\n",
    "#         output=${workingDir}/squeezy/derivatives/mts/caudalACC/IC_0${dim}\n",
    "#         mkdir -p ${output}\n",
    "#         #fslmeants -i ${subj} -o ${output}/mts_IC_0${dim}_${sub}.txt -m ${HCP_mask} -v\n",
    "#         fslmaths ${subj} -Tmean -mas ${HCP_mask} ${output}/Tmean_IC_0${dim}_${sub}.txt \n",
    "#     done\n",
    "# done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "# Notes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing resting state data\n",
    "\n",
    "* The Raw DREAM data was taken to run melodic on. To be consistent with the previous processed data, the .fsf file created from the melodic gui was taken from another participant and the ID changed.  \n",
    "* It is advisable to run the three different steps independently to make sure it doesnt fail at any point. \n",
    "* ICA AROMA is an alternative to fix\n",
    "* The new cluster has been a pain in the hole and the .fsf files had to be recreated with the new version of fsl. \n",
    "* Fix requires r and matlab modules to be loaded on the new cluster.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. feat was then fun on these three participants: (produces filtered_func.nii)\n",
    "\n",
    "An example.fsf file needs to be created. A template is included at the bottom. The paths which are hardcoded into it need to be changed to suit the correct paths. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%shell\n",
    "\n",
    "# Variables\n",
    "example=$workingDir/DREAM_example.fsf\n",
    "outputDir=$workingDir/${projectLabel}\n",
    "\n",
    "# /group/DREAM/REST/REST_PAT/REST_067_v1/REST_067_v1.nii.gz\n",
    "\n",
    "subj=\"067_v1 068_v1  069_v1\"\n",
    "\n",
    "for i in $subj ;\n",
    "do\n",
    "    echo $i\n",
    "    # REST\n",
    "    echo ${example} | sed 's/XX/'REST_${i}'/g' $example > $outputDir/${i}.fsf  \n",
    "    # STUCT\n",
    "    echo $outputDir/${i}.fsf | sed 's/YY/'${i}'/g' $outputDir/${i}.fsf > $outputDir/rest_${i}.fsf\n",
    "    # run feat\n",
    "    echo \"feat rest_${i}.fsf\" >> ${TMPDIR}/featJobs.txt\n",
    "    done\n",
    "\n",
    "    # Run job\n",
    "    hpcSubmit ${TMPDIR}/featJobs.txt 12:00:00 4 6Gb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
